# Floating point number




## wikipedia [Floating-point arithmetic](https://en.wikipedia.org/wiki/Floating-point_arithmetic)

In [computing](https://en.wikipedia.org/wiki/Computing), **floating-point arithmetic** (**FP**) is arithmetic using formulaic representation of [real numbers](https://en.wikipedia.org/wiki/Real_number) as an **approximation** so as to support a [trade-off](https://en.wikipedia.org/wiki/Trade-off) between range and [precision](https://en.wikipedia.org/wiki/Accuracy_and_precision). For this reason, floating-point computation is often found in systems which include very small and very large [real numbers](https://en.wikipedia.org/wiki/Real_numbers), which require fast processing times. A number is, in general, represented approximately to a fixed number of [significant digits](https://en.wikipedia.org/wiki/Significant_figures) (the [significand](https://en.wikipedia.org/wiki/Significand)) and scaled using an [exponent](https://en.wikipedia.org/wiki/Exponentiation) in some fixed **base**; the base for the scaling is normally two, ten, or sixteen. A number that can be represented exactly is of the following form:


@@ -173,17 +186,7 @@ In addition to loss of significance, inability to represent numbers such as π a

#### Minimizing the effect of accuracy problems

## wikipedia [Single-precision floating-point format](https://en.wikipedia.org/wiki/Single-precision_floating-point_format)

**Single-precision floating-point format** is a [computer number format](https://en.wikipedia.org/wiki/Computer_number_format), usually occupying [32 bits](https://en.wikipedia.org/wiki/32_bits) in [computer memory](https://en.wikipedia.org/wiki/Computer_memory); it represents a wide [dynamic range](https://en.wikipedia.org/wiki/Dynamic_range) of numeric values by using a [floating radix point](https://en.wikipedia.org/wiki/Floating_point).

A floating-point variable can represent a wider range of numbers than a [fixed-point](https://en.wikipedia.org/wiki/Fixed-point_arithmetic) variable of the same bit width at the cost of precision. A [signed](https://en.wikipedia.org/wiki/Signedness)32-bit [integer](https://en.wikipedia.org/wiki/Integer) variable has a maximum value of $2^{31} − 1 = 2,147,483,647$, whereas an IEEE 754 32-bit base-2 floating-point variable has a maximum value of $(2 − 2^{−23}) × 2^{127} ≈ 3.4028235 × 10^{38}$. All integers with 6 or fewer [significant decimal digits](https://en.wikipedia.org/wiki/Significant_figures), and any number that can be written as 2n such that n is a whole number from -126 to 127, can be converted into an IEEE 754 floating-point value without loss of precision.

In the [IEEE 754-2008](https://en.wikipedia.org/wiki/IEEE_754-2008) [standard](https://en.wikipedia.org/wiki/Standardization), the 32-bit base-2 format is officially referred to as **binary32**; it was called **single** in [IEEE 754-1985](https://en.wikipedia.org/wiki/IEEE_754-1985). IEEE 754 specifies additional floating-point types, such as 64-bit base-2 *double precision* and, more recently, base-10 representations.

One of the first [programming languages](https://en.wikipedia.org/wiki/Programming_language) to provide single- and double-precision floating-point data types was [Fortran](https://en.wikipedia.org/wiki/Fortran). Before the widespread adoption of IEEE 754-1985, the representation and properties of floating-point data types depended on the [computer manufacturer](https://en.wikipedia.org/wiki/Computer_manufacturer) and computer model, and upon decisions made by programming-language designers. E.g., [GW-BASIC](https://en.wikipedia.org/wiki/GW-BASIC)'s single-precision data type was the [32-bit MBF](https://en.wikipedia.org/wiki/32-bit_MBF) floating-point format.

Single precision is termed *REAL* in [Fortran](https://en.wikipedia.org/wiki/Fortran),[[1\]](https://en.wikipedia.org/wiki/Single-precision_floating-point_format#cite_note-1) *SINGLE-FLOAT* in [Common Lisp](https://en.wikipedia.org/wiki/Common_Lisp),[[2\]](https://en.wikipedia.org/wiki/Single-precision_floating-point_format#cite_note-2) *float* in [C](https://en.wikipedia.org/wiki/C_(programming_language)), [C++](https://en.wikipedia.org/wiki/C%2B%2B), [C#](https://en.wikipedia.org/wiki/C_Sharp_(programming_language)), [Java](https://en.wikipedia.org/wiki/Java_(programming_language)),[[3\]](https://en.wikipedia.org/wiki/Single-precision_floating-point_format#cite_note-3) *Float* in [Haskell](https://en.wikipedia.org/wiki/Haskell_(programming_language)),[[4\]](https://en.wikipedia.org/wiki/Single-precision_floating-point_format#cite_note-4) and *Single* in [Object Pascal](https://en.wikipedia.org/wiki/Object_Pascal) ([Delphi](https://en.wikipedia.org/wiki/Delphi_(programming_language))), [Visual Basic](https://en.wikipedia.org/wiki/Visual_Basic), and [MATLAB](https://en.wikipedia.org/wiki/MATLAB). However, *float* in [Python](https://en.wikipedia.org/wiki/Python_(programming_language)), [Ruby](https://en.wikipedia.org/wiki/Ruby_(programming_language)), [PHP](https://en.wikipedia.org/wiki/PHP), and [OCaml](https://en.wikipedia.org/wiki/OCaml) and *single* in versions of [Octave](https://en.wikipedia.org/wiki/GNU_Octave) before 3.2 refer to [double-precision](https://en.wikipedia.org/wiki/Double-precision_floating-point_format) numbers. In most implementations of [PostScript](https://en.wikipedia.org/wiki/PostScript), and some [embedded systems](https://en.wikipedia.org/wiki/Embedded_systems), the only supported precision is single.

