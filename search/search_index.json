{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u5173\u4e8e\u672c\u9879\u76ee \u672c\u9879\u76ee\u4e3b\u8981\u8bb0\u5f55\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u76f8\u5173\u7684\u77e5\u8bc6\u3002","title":"Introduction"},{"location":"#_1","text":"\u672c\u9879\u76ee\u4e3b\u8981\u8bb0\u5f55\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u76f8\u5173\u7684\u77e5\u8bc6\u3002","title":"\u5173\u4e8e\u672c\u9879\u76ee"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/","text":"1.2 \u8ba1\u7b97\u673a\u53d1\u5c55\u7b80\u53f2 \u53c2\u89c1\uff1a Computer 1.2.4 \u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807 \u541e\u5410\u91cf \u54cd\u5e94\u65f6\u95f4 \u5229\u7528\u7387 \u5904\u7406\u673a\u5b57\u957f \u6307\u5904\u7406\u673a \u8fd0\u7b97\u5668 \uff08ALU\uff09\u4e2d\u4e00\u6b21\u80fd\u591f\u5b8c\u6210\u4e8c\u8fdb\u5236\u6570\u8fd0\u7b97\u7684 \u4f4d\u6570 \uff0c\u598232\u4f4d\uff0c64\u4f4d\uff1b NOTE : \u8fd9\u5e94\u8be5\u5c31\u662f\u6211\u4eec\u5e73\u65f6\u6240\u8bf4\u768432\u4f4d\uff0c\u621664\u4f4d\uff1b\u4e00\u6b21\u80fd\u591f\u5b8c\u6210\u4e8c\u8fdb\u5236\u6570\u7684\u8fd0\u7b97\uff0c\u5176\u5b9e\u8574\u542b\u4e2d\uff0cCPU\u4e00\u6b21CPU\u4e00\u6b21\u6027\u80fd\u8bfb\u53d6\u6570\u636e\u7684\u4e8c\u8fdb\u5236\u4f4d\u6570\u3002\u53c2\u89c1 Redis\u5185\u5b58\u7ba1\u7406\u7684\u57fa\u77f3zmallc.c\u6e90\u7801\u89e3\u8bfb\uff08\u4e00\uff09 \uff1b Data alignment: Straighten up and fly right \u4e0a\u8ff0\u4e00\u6b21\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\u662f\u6307\u4e00\u4e2a\u6307\u4ee4\u5468\u671f\uff1f \u603b\u7ebf\u5bbd\u5ea6 \u4e00\u822c\u6307CPU\u4e2d \u8fd0\u7b97\u5668 \u4e0e \u5b58\u50a8\u5668 \u4e4b\u95f4\u8fdb\u884c\u4e92\u8054\u7684\u5185\u90e8\u603b\u7ebf\u4e8c\u8fdb\u5236\u4f4d\u6570\u3002 \u4e3b\u9891/\u65f6\u949f\u5468\u671f CPU\u7684\u5de5\u4f5c\u8282\u62cd\u53d7 \u4e3b\u65f6\u949f \u7684\u63a7\u5236\uff0c \u4e3b\u65f6\u949f \u4e0d\u65ad\u4ea7\u751f\u56fa\u5b9a\u9891\u7387\u7684\u65f6\u949f\uff0c \u4e3b\u65f6\u949f\u9891\u7387 \uff08 f \uff09\u53eb CPU\u4e3b\u9891 \u3002\u5ea6\u91cf\u5355\u4f4d\u662f MHz , GHz NOTE : \u4e3b\u9891\u7684\u542b\u4e49\u5c31\u662fCPU\u4e3b\u65f6\u949f\u7684\u9891\u7387\uff1b \u9891\u7387\u7684\u542b\u4e49\u662f\u4e00\u79d2\u949f\u6267\u884c\u591a\u5c11\u6b21\uff1b \u4e3b\u9891\u7684\u5012\u6570\u79f0\u4e3a CPU\u65f6\u949f\u5468\u671f \uff08 T \uff09\uff0c T=1/f \uff0c\u5ea6\u91cf\u5355\u4f4d\u662f us \uff0c ns \u3002 NOTE : CPU\u65f6\u949f\u5468\u671f \u5728\u300a5.2.1 \u6307\u4ee4\u5468\u671f\u7684\u57fa\u672c\u6982\u5ff5\u300b\u4e2d\u6709\u4ecb\u7ecd\uff1b\u4ece\u4e0a\u8ff0\u5173\u7cfb\u53ef\u4ee5\u770b\u51fa\uff0cCPU\u4e3b\u9891\u548cCPU\u65f6\u949f\u5468\u671f\u5bc6\u5207\u76f8\u5173\uff1b\u4e3b\u65f6\u949f\u5219\u5728\u300a5.3.2 \u65f6\u5e8f\u4fe1\u53f7\u4ea7\u751f\u5668\u300b\u4e2d\u6709\u4ecb\u7ecd\uff1b CPU\u6267\u884c\u65f6\u95f4 \u8868\u793aCPU\u6267\u884c\u4e00\u822c\u7a0b\u5e8f\u6240\u5360\u7528\u7684CPU\u65f6\u95f4\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e0b\u9762\u516c\u5f0f\u8ba1\u7b97\uff1a CPU\u6267\u884c\u65f6\u95f4 = CPU\u65f6\u949f\u5468\u671f\u6570 * CPU\u65f6\u949f\u5468\u671f CPI \u8868\u793a\u6bcf\u6761\u6307\u4ee4\u5468\u671f\u6570\uff0c\u5373\u6267\u884c\u4e00\u6761\u6307\u4ee4\u6240\u9700\u7684\u5e73\u5747\u65f6\u949f\u5468\u671f\u6570\uff0c\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u8ba1\u7b97\uff1a CPI = \u6267\u884c\u67d0\u6bb5\u7a0b\u5e8f\u6240\u9700\u7684CPU\u65f6\u949f\u5468\u671f\u6570 / \u7a0b\u5e8f\u5305\u542b\u7684\u6307\u4ee4\u6761\u6570 FLOPS \u8868\u793a\u6bcf\u79d2\u6267\u884c\u6d6e\u70b9\u64cd\u4f5c\u7684\u6b21\u6570\uff0c\u7528\u6765\u8861\u91cf\u673a\u5668\u6d6e\u70b9\u64cd\u4f5c\u7684\u6027\u80fd\u3002\u7528\u4e0b\u5f0f\u8ba1\u7b97\uff1a FLOPS = \u7a0b\u5e8f\u4e2d\u6d6e\u70b9\u64cd\u4f5c\u6b21\u6570 / \u7a0b\u5e8f\u6267\u884c\u65f6\u95f4","title":"1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#12","text":"\u53c2\u89c1\uff1a Computer","title":"1.2 \u8ba1\u7b97\u673a\u53d1\u5c55\u7b80\u53f2"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#124","text":"","title":"1.2.4 \u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#_1","text":"","title":"\u541e\u5410\u91cf"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#_2","text":"","title":"\u54cd\u5e94\u65f6\u95f4"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#_3","text":"","title":"\u5229\u7528\u7387"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#_4","text":"\u6307\u5904\u7406\u673a \u8fd0\u7b97\u5668 \uff08ALU\uff09\u4e2d\u4e00\u6b21\u80fd\u591f\u5b8c\u6210\u4e8c\u8fdb\u5236\u6570\u8fd0\u7b97\u7684 \u4f4d\u6570 \uff0c\u598232\u4f4d\uff0c64\u4f4d\uff1b NOTE : \u8fd9\u5e94\u8be5\u5c31\u662f\u6211\u4eec\u5e73\u65f6\u6240\u8bf4\u768432\u4f4d\uff0c\u621664\u4f4d\uff1b\u4e00\u6b21\u80fd\u591f\u5b8c\u6210\u4e8c\u8fdb\u5236\u6570\u7684\u8fd0\u7b97\uff0c\u5176\u5b9e\u8574\u542b\u4e2d\uff0cCPU\u4e00\u6b21CPU\u4e00\u6b21\u6027\u80fd\u8bfb\u53d6\u6570\u636e\u7684\u4e8c\u8fdb\u5236\u4f4d\u6570\u3002\u53c2\u89c1 Redis\u5185\u5b58\u7ba1\u7406\u7684\u57fa\u77f3zmallc.c\u6e90\u7801\u89e3\u8bfb\uff08\u4e00\uff09 \uff1b Data alignment: Straighten up and fly right \u4e0a\u8ff0\u4e00\u6b21\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\u662f\u6307\u4e00\u4e2a\u6307\u4ee4\u5468\u671f\uff1f","title":"\u5904\u7406\u673a\u5b57\u957f"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#_5","text":"\u4e00\u822c\u6307CPU\u4e2d \u8fd0\u7b97\u5668 \u4e0e \u5b58\u50a8\u5668 \u4e4b\u95f4\u8fdb\u884c\u4e92\u8054\u7684\u5185\u90e8\u603b\u7ebf\u4e8c\u8fdb\u5236\u4f4d\u6570\u3002","title":"\u603b\u7ebf\u5bbd\u5ea6"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#_6","text":"CPU\u7684\u5de5\u4f5c\u8282\u62cd\u53d7 \u4e3b\u65f6\u949f \u7684\u63a7\u5236\uff0c \u4e3b\u65f6\u949f \u4e0d\u65ad\u4ea7\u751f\u56fa\u5b9a\u9891\u7387\u7684\u65f6\u949f\uff0c \u4e3b\u65f6\u949f\u9891\u7387 \uff08 f \uff09\u53eb CPU\u4e3b\u9891 \u3002\u5ea6\u91cf\u5355\u4f4d\u662f MHz , GHz NOTE : \u4e3b\u9891\u7684\u542b\u4e49\u5c31\u662fCPU\u4e3b\u65f6\u949f\u7684\u9891\u7387\uff1b \u9891\u7387\u7684\u542b\u4e49\u662f\u4e00\u79d2\u949f\u6267\u884c\u591a\u5c11\u6b21\uff1b \u4e3b\u9891\u7684\u5012\u6570\u79f0\u4e3a CPU\u65f6\u949f\u5468\u671f \uff08 T \uff09\uff0c T=1/f \uff0c\u5ea6\u91cf\u5355\u4f4d\u662f us \uff0c ns \u3002 NOTE : CPU\u65f6\u949f\u5468\u671f \u5728\u300a5.2.1 \u6307\u4ee4\u5468\u671f\u7684\u57fa\u672c\u6982\u5ff5\u300b\u4e2d\u6709\u4ecb\u7ecd\uff1b\u4ece\u4e0a\u8ff0\u5173\u7cfb\u53ef\u4ee5\u770b\u51fa\uff0cCPU\u4e3b\u9891\u548cCPU\u65f6\u949f\u5468\u671f\u5bc6\u5207\u76f8\u5173\uff1b\u4e3b\u65f6\u949f\u5219\u5728\u300a5.3.2 \u65f6\u5e8f\u4fe1\u53f7\u4ea7\u751f\u5668\u300b\u4e2d\u6709\u4ecb\u7ecd\uff1b","title":"\u4e3b\u9891/\u65f6\u949f\u5468\u671f"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#cpu","text":"\u8868\u793aCPU\u6267\u884c\u4e00\u822c\u7a0b\u5e8f\u6240\u5360\u7528\u7684CPU\u65f6\u95f4\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e0b\u9762\u516c\u5f0f\u8ba1\u7b97\uff1a CPU\u6267\u884c\u65f6\u95f4 = CPU\u65f6\u949f\u5468\u671f\u6570 * CPU\u65f6\u949f\u5468\u671f","title":"CPU\u6267\u884c\u65f6\u95f4"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#cpi","text":"\u8868\u793a\u6bcf\u6761\u6307\u4ee4\u5468\u671f\u6570\uff0c\u5373\u6267\u884c\u4e00\u6761\u6307\u4ee4\u6240\u9700\u7684\u5e73\u5747\u65f6\u949f\u5468\u671f\u6570\uff0c\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u8ba1\u7b97\uff1a CPI = \u6267\u884c\u67d0\u6bb5\u7a0b\u5e8f\u6240\u9700\u7684CPU\u65f6\u949f\u5468\u671f\u6570 / \u7a0b\u5e8f\u5305\u542b\u7684\u6307\u4ee4\u6761\u6570","title":"CPI"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u7b80\u53f2/#flops","text":"\u8868\u793a\u6bcf\u79d2\u6267\u884c\u6d6e\u70b9\u64cd\u4f5c\u7684\u6b21\u6570\uff0c\u7528\u6765\u8861\u91cf\u673a\u5668\u6d6e\u70b9\u64cd\u4f5c\u7684\u6027\u80fd\u3002\u7528\u4e0b\u5f0f\u8ba1\u7b97\uff1a FLOPS = \u7a0b\u5e8f\u4e2d\u6d6e\u70b9\u64cd\u4f5c\u6b21\u6570 / \u7a0b\u5e8f\u6267\u884c\u65f6\u95f4","title":"FLOPS"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/","text":"1.2 \u8ba1\u7b97\u673a\u53d1\u5c55\u7b80\u53f2 \u53c2\u89c1\uff1a Computer 1.2.4 \u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807 \u541e\u5410\u91cf \u54cd\u5e94\u65f6\u95f4 \u5229\u7528\u7387 \u5904\u7406\u673a\u5b57\u957f \u6307\u5904\u7406\u673a \u8fd0\u7b97\u5668 \u4e2d\u4e00\u6b21\u80fd\u591f\u5b8c\u6210\u4e8c\u8fdb\u5236\u6570\u8fd0\u7b97\u7684 \u4f4d\u6570 \uff0c\u598232\u4f4d\uff0c64\u4f4d\uff1b SUMMARY : \u8fd9\u5e94\u8be5\u5c31\u662f\u6211\u4eec\u5e73\u65f6\u6240\u8bf4\u768432\u4f4d\uff0c\u621664\u4f4d\uff1b\u4e00\u6b21\u80fd\u591f\u5b8c\u6210\u4e8c\u8fdb\u5236\u6570\u7684\u8fd0\u7b97\uff0c\u5176\u5b9e\u8574\u542b\u4e2d\uff0cCPU\u4e00\u6b21CPU\u4e00\u6b21\u6027\u80fd\u8bfb\u53d6\u6570\u636e\u7684\u4e8c\u8fdb\u5236\u4f4d\u6570\u3002\u53c2\u89c1 Redis\u5185\u5b58\u7ba1\u7406\u7684\u57fa\u77f3zmallc.c\u6e90\u7801\u89e3\u8bfb\uff08\u4e00\uff09 \uff1b Data alignment: Straighten up and fly right SUMMARY : \u4e0a\u8ff0\u4e00\u6b21\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\u662f\u6307\u4e00\u4e2a\u6307\u4ee4\u5468\u671f\uff1f \u603b\u7ebf\u5bbd\u5ea6 \u4e00\u822c\u6307CPU\u4e2d \u8fd0\u7b97\u5668 \u4e0e \u5b58\u50a8\u5668 \u4e4b\u95f4\u8fdb\u884c\u4e92\u8054\u7684\u5185\u90e8\u603b\u7ebf\u4e8c\u8fdb\u5236\u4f4d\u6570\u3002 \u4e3b\u9891/\u65f6\u949f\u5468\u671f CPU\u7684\u5de5\u4f5c\u8282\u62cd\u53d7 \u4e3b\u65f6\u949f \u7684\u63a7\u5236\uff0c \u4e3b\u65f6\u949f \u4e0d\u65ad\u4ea7\u751f\u56fa\u5b9a\u9891\u7387\u7684\u65f6\u949f\uff0c \u4e3b\u65f6\u949f\u9891\u7387 \uff08 f \uff09\u53eb CPU\u4e3b\u9891 \u3002\u5ea6\u91cf\u5355\u4f4d\u662f MHz , GHz SUMMARY : \u4e3b\u9891\u7684\u542b\u4e49\u5c31\u662fCPU\u4e3b\u65f6\u949f\u7684\u9891\u7387\uff1b SUMMARY : \u9891\u7387\u7684\u542b\u4e49\u662f\u4e00\u79d2\u949f\u6267\u884c\u591a\u5c11\u6b21\uff1b \u4e3b\u9891\u7684\u5012\u6570\u79f0\u4e3a CPU\u65f6\u949f\u5468\u671f \uff08 T \uff09\uff0c T=1/f \uff0c\u5ea6\u91cf\u5355\u4f4d\u662f us \uff0c ns \u3002 SUMMARY : CPU\u65f6\u949f\u5468\u671f \u5728\u300a5.2.1 \u6307\u4ee4\u5468\u671f\u7684\u57fa\u672c\u6982\u5ff5\u300b\u4e2d\u6709\u4ecb\u7ecd\uff1b\u4ece\u4e0a\u8ff0\u5173\u7cfb\u53ef\u4ee5\u770b\u51fa\uff0cCPU\u4e3b\u9891\u548cCPU\u65f6\u949f\u5468\u671f\u5bc6\u5207\u76f8\u5173\uff1b\u4e3b\u65f6\u949f\u5219\u5728\u300a5.3.2 \u65f6\u5e8f\u4fe1\u53f7\u4ea7\u751f\u5668\u300b\u4e2d\u6709\u4ecb\u7ecd\uff1b SUMMARY : \u53c2\u89c1 Memory Alignment CPU\u6267\u884c\u65f6\u95f4 \u8868\u793aCPU\u6267\u884c\u4e00\u822c\u7a0b\u5e8f\u6240\u5360\u7528\u7684CPU\u65f6\u95f4\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e0b\u9762\u516c\u5f0f\u8ba1\u7b97\uff1a CPU\u6267\u884c\u65f6\u95f4 = CPU\u65f6\u949f\u5468\u671f\u6570 * CPU\u65f6\u949f\u5468\u671f CPI \u8868\u793a\u6bcf\u6761\u6307\u4ee4\u5468\u671f\u6570\uff0c\u5373\u6267\u884c\u4e00\u6761\u6307\u4ee4\u6240\u9700\u7684\u5e73\u5747\u65f6\u949f\u5468\u671f\u6570\uff0c\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u8ba1\u7b97\uff1a CPI = \u6267\u884c\u67d0\u6bb5\u7a0b\u5e8f\u6240\u9700\u7684CPU\u65f6\u949f\u5468\u671f\u6570 / \u7a0b\u5e8f\u5305\u542b\u7684\u6307\u4ee4\u6761\u6570 FLOPS \u8868\u793a\u6bcf\u79d2\u6267\u884c\u6d6e\u70b9\u64cd\u4f5c\u7684\u6b21\u6570\uff0c\u7528\u6765\u8861\u91cf\u673a\u5668\u6d6e\u70b9\u64cd\u4f5c\u7684\u6027\u80fd\u3002\u7528\u4e0b\u5f0f\u8ba1\u7b97\uff1a FLOPS = \u7a0b\u5e8f\u4e2d\u6d6e\u70b9\u64cd\u4f5c\u6b21\u6570 / \u7a0b\u5e8f\u6267\u884c\u65f6\u95f4","title":"1.2 \u8ba1\u7b97\u673a\u53d1\u5c55\u7b80\u53f2"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#12","text":"\u53c2\u89c1\uff1a Computer","title":"1.2 \u8ba1\u7b97\u673a\u53d1\u5c55\u7b80\u53f2"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#124","text":"","title":"1.2.4 \u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#_1","text":"","title":"\u541e\u5410\u91cf"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#_2","text":"","title":"\u54cd\u5e94\u65f6\u95f4"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#_3","text":"","title":"\u5229\u7528\u7387"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#_4","text":"\u6307\u5904\u7406\u673a \u8fd0\u7b97\u5668 \u4e2d\u4e00\u6b21\u80fd\u591f\u5b8c\u6210\u4e8c\u8fdb\u5236\u6570\u8fd0\u7b97\u7684 \u4f4d\u6570 \uff0c\u598232\u4f4d\uff0c64\u4f4d\uff1b SUMMARY : \u8fd9\u5e94\u8be5\u5c31\u662f\u6211\u4eec\u5e73\u65f6\u6240\u8bf4\u768432\u4f4d\uff0c\u621664\u4f4d\uff1b\u4e00\u6b21\u80fd\u591f\u5b8c\u6210\u4e8c\u8fdb\u5236\u6570\u7684\u8fd0\u7b97\uff0c\u5176\u5b9e\u8574\u542b\u4e2d\uff0cCPU\u4e00\u6b21CPU\u4e00\u6b21\u6027\u80fd\u8bfb\u53d6\u6570\u636e\u7684\u4e8c\u8fdb\u5236\u4f4d\u6570\u3002\u53c2\u89c1 Redis\u5185\u5b58\u7ba1\u7406\u7684\u57fa\u77f3zmallc.c\u6e90\u7801\u89e3\u8bfb\uff08\u4e00\uff09 \uff1b Data alignment: Straighten up and fly right SUMMARY : \u4e0a\u8ff0\u4e00\u6b21\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\u662f\u6307\u4e00\u4e2a\u6307\u4ee4\u5468\u671f\uff1f","title":"\u5904\u7406\u673a\u5b57\u957f"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#_5","text":"\u4e00\u822c\u6307CPU\u4e2d \u8fd0\u7b97\u5668 \u4e0e \u5b58\u50a8\u5668 \u4e4b\u95f4\u8fdb\u884c\u4e92\u8054\u7684\u5185\u90e8\u603b\u7ebf\u4e8c\u8fdb\u5236\u4f4d\u6570\u3002","title":"\u603b\u7ebf\u5bbd\u5ea6"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#_6","text":"CPU\u7684\u5de5\u4f5c\u8282\u62cd\u53d7 \u4e3b\u65f6\u949f \u7684\u63a7\u5236\uff0c \u4e3b\u65f6\u949f \u4e0d\u65ad\u4ea7\u751f\u56fa\u5b9a\u9891\u7387\u7684\u65f6\u949f\uff0c \u4e3b\u65f6\u949f\u9891\u7387 \uff08 f \uff09\u53eb CPU\u4e3b\u9891 \u3002\u5ea6\u91cf\u5355\u4f4d\u662f MHz , GHz SUMMARY : \u4e3b\u9891\u7684\u542b\u4e49\u5c31\u662fCPU\u4e3b\u65f6\u949f\u7684\u9891\u7387\uff1b SUMMARY : \u9891\u7387\u7684\u542b\u4e49\u662f\u4e00\u79d2\u949f\u6267\u884c\u591a\u5c11\u6b21\uff1b \u4e3b\u9891\u7684\u5012\u6570\u79f0\u4e3a CPU\u65f6\u949f\u5468\u671f \uff08 T \uff09\uff0c T=1/f \uff0c\u5ea6\u91cf\u5355\u4f4d\u662f us \uff0c ns \u3002 SUMMARY : CPU\u65f6\u949f\u5468\u671f \u5728\u300a5.2.1 \u6307\u4ee4\u5468\u671f\u7684\u57fa\u672c\u6982\u5ff5\u300b\u4e2d\u6709\u4ecb\u7ecd\uff1b\u4ece\u4e0a\u8ff0\u5173\u7cfb\u53ef\u4ee5\u770b\u51fa\uff0cCPU\u4e3b\u9891\u548cCPU\u65f6\u949f\u5468\u671f\u5bc6\u5207\u76f8\u5173\uff1b\u4e3b\u65f6\u949f\u5219\u5728\u300a5.3.2 \u65f6\u5e8f\u4fe1\u53f7\u4ea7\u751f\u5668\u300b\u4e2d\u6709\u4ecb\u7ecd\uff1b SUMMARY : \u53c2\u89c1 Memory Alignment","title":"\u4e3b\u9891/\u65f6\u949f\u5468\u671f"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#cpu","text":"\u8868\u793aCPU\u6267\u884c\u4e00\u822c\u7a0b\u5e8f\u6240\u5360\u7528\u7684CPU\u65f6\u95f4\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e0b\u9762\u516c\u5f0f\u8ba1\u7b97\uff1a CPU\u6267\u884c\u65f6\u95f4 = CPU\u65f6\u949f\u5468\u671f\u6570 * CPU\u65f6\u949f\u5468\u671f","title":"CPU\u6267\u884c\u65f6\u95f4"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#cpi","text":"\u8868\u793a\u6bcf\u6761\u6307\u4ee4\u5468\u671f\u6570\uff0c\u5373\u6267\u884c\u4e00\u6761\u6307\u4ee4\u6240\u9700\u7684\u5e73\u5747\u65f6\u949f\u5468\u671f\u6570\uff0c\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u8ba1\u7b97\uff1a CPI = \u6267\u884c\u67d0\u6bb5\u7a0b\u5e8f\u6240\u9700\u7684CPU\u65f6\u949f\u5468\u671f\u6570 / \u7a0b\u5e8f\u5305\u542b\u7684\u6307\u4ee4\u6761\u6570","title":"CPI"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.2-\u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807/#flops","text":"\u8868\u793a\u6bcf\u79d2\u6267\u884c\u6d6e\u70b9\u64cd\u4f5c\u7684\u6b21\u6570\uff0c\u7528\u6765\u8861\u91cf\u673a\u5668\u6d6e\u70b9\u64cd\u4f5c\u7684\u6027\u80fd\u3002\u7528\u4e0b\u5f0f\u8ba1\u7b97\uff1a FLOPS = \u7a0b\u5e8f\u4e2d\u6d6e\u70b9\u64cd\u4f5c\u6b21\u6570 / \u7a0b\u5e8f\u6267\u884c\u65f6\u95f4","title":"FLOPS"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/","text":"1.3\u8ba1\u7b97\u673a\u7684\u786c\u4ef6 1.3.1 \u786c\u4ef6\u7ec4\u6210\u8981\u7d20 \u4f7f\u7528\u6253\u7b97\u76d8\u6765\u8bf4\u660e\u8ba1\u7b97\u673a\u7684\u4e3b\u8981\u7ec4\u6210\u548c\u5de5\u4f5c\u539f\u7406\u3002\u7ed9\u5b9a\u4e00\u4e2a\u7b97\u76d8\u3001\u4e00\u5f20\u5e26\u6709\u6a2a\u683c\u7684\u7eb8\u3001\u4e00\u652f\u7b14\uff0c\u8981\u6c42\u8ba1\u7b97y=ax+b-c\u3002\u4e0b\u9762\u5c06\u89e3\u9898\u6b65\u9aa4\u8bb0\u5f55\u5728\u5e26\u6709\u6a2a\u683c\u7684\u7eb8\u5e26\u4e0a\uff1a \u88681.3\u89e3\u9898\u6b65\u9aa4\u548c\u6570\u636e\u8bb0\u5f55\u5728\u6a2a\u683c\u7eb8\u4e0a \u884c\u6570 \u89e3\u9898\u6b65\u9aa4\u548c\u6570\u636e \u8bf4\u660e 1 \u53d6\u6570 \uff089\uff09->\u7b97\u76d8 \uff089\uff09\u8868\u793a\u7b2c9\u884c\u7684\u6570a\uff0c\u4e0b\u540c 2 \u4e58\u6cd5 \uff0812\uff09->\u7b97\u76d8 \u5b8c\u6210 a*x \uff0c\u7ed3\u679c\u5728\u7b97\u76d8\u4e0a 3 \u52a0\u6cd5 \uff0810\uff09->\u7b97\u76d8 \u5b8c\u6210 a*x+b \uff0c\u7ed3\u679c\u5728\u7b97\u76d8\u4e0a 4 \u51cf\u6cd5 \uff0811\uff09->\u7b97\u76d8 \u5b8c\u6210 y=a*x+b-c \uff0c\u7ed3\u679c\u5728\u7b97\u76d8\u4e0a 5 \u5b58\u6570 y->13 \u7b97\u76d8\u4e0a\u7684y\u503c\u8bb0\u523013\u884c 6 \u8f93\u51fa \u5c06\u7b97\u76d8\u4e0a\u7684y\u503c\u5199\u51fa\u6765\u7ed9\u4eba\u770b 7 \u505c\u6b62 8 9 a \u6570\u636e 10 b \u6570\u636e 11 c \u6570\u636e 12 x \u6570\u636e 13 y \u6570\u636e \u5728\u7535\u5b50\u8ba1\u7b97\u673a\u4e2d\uff1a \u8fd0\u7b97\u5668 \u76f8\u5f53\u4e8e\u7b97\u76d8 \u5b58\u50a8\u5668 \u76f8\u5f53\u4e8e\u7eb8 \u63a7\u5236\u5668 \u76f8\u5f53\u4e8e\u4eba\u7684\u5927\u8111\uff08\u63a7\u5236\u7740\u6574\u4e2a\u8ba1\u7b97\u8fc7\u7a0b\uff09 |<--> \u5b58\u50a8\u5668 | \u7cfb |<--> \u8fd0\u7b97\u5668 \u7edf | \u603b |<--> \u63a7\u5236\u5668 \u7ebf | |<--> \u9002\u914d\u5668 | | | | \u8f93\u5165\u8bbe\u5907 \u8f93\u51fa\u8bbe\u5907 CPU = \u8fd0\u7b97\u5668 + \u63a7\u5236\u5668 1.3.2 \u8fd0\u7b97\u5668 \u53c2\u89c1\uff1a ALU \u5b57\u957f\uff1a\u8fd0\u7b97\u5668\u7684\u957f\u5ea6 1.3.3 \u5b58\u50a8\u5668 \u53c2\u89c1\uff1a Computer memory 1.3.4 \u63a7\u5236\u5668 \u53c2\u89c1\uff1a Control unit \u63a7\u5236\u5668\u7684\u4efb\u52a1\u662f\u4ece\u5185\u5b58\u4e2d\u53d6\u51fa\u89e3\u9898\u6b65\u9aa4\u52a0\u4ee5\u5206\u6790\uff0c\u7136\u540e\u6267\u884c\u67d0\u79cd\u64cd\u4f5c\uff1b NOTE: \u8bfb\u53d6\u6307\u4ee4\u548c\u8bfb\u53d6\u6570\u636e\u90fd\u662f\u7531\u63a7\u5236\u5668\u6765\u5b8c\u6210\u7684\uff1b\u6240\u4ee5\u63a7\u5236\u5668\u9700\u8981\u4e86\u89e3\u6307\u4ee4\u7684\u683c\u5f0f 1. \u8ba1\u7b97\u7a0b\u5e8f \u88681.4\u8ba1\u7b97y=ax+b-c\u7684\u7a0b\u5e8f \u6307\u4ee4\u5730\u5740 \u64cd\u4f5c\u7801 \u5730\u5740\u7801 \u6307\u4ee4\u64cd\u4f5c\u5185\u5bb9 \u8bf4\u660e 1 \u53d6\u6570 9 (9) -> A \u5c06\u5b58\u50a8\u56689\u53f7\u5730\u5740\u7684\u6570\u8bfb\u5165\u5230\u8fd0\u7b97\u5668A 2 \u4e58\u6cd5 12 (A) * (12) -> A \u5b8c\u6210 a*x \uff0c\u7ed3\u679c\u4fdd\u7559\u7740\u8fd0\u7b97\u5668A 3 \u52a0\u6cd5 10 (A) + (10) -> A \u5b8c\u6210 a*x+b \uff0c\u7ed3\u679c\u4fdd\u7559\u7740\u8fd0\u7b97\u5668A 4 \u51cf\u6cd5 11 (A) - (11) -> A \u5b8c\u6210 a*x+b-c \uff0c\u7ed3\u679c\u4fdd\u7559\u7740\u8fd0\u7b97\u5668A 5 \u5b58\u6570 13 A->13 \u8fd0\u7b97\u5668A\u4e2d\u7684\u7ed3\u679cy\u9001\u5165\u5230\u5b58\u50a8\u566813\u53f7\u5730\u5740 6 \u6253\u5370 7 \u505c\u6b62 8 \u6570\u636e\u5730\u5740 \u6570\u636e \u8bf4\u660e 9 a 10 b 11 c 12 x 13 y \u88681.4\u662f\u4e00\u4e2a\u975e\u5e38\u597d\u7684\u4f8b\u5b50\uff0c\u8fd9\u4e2a\u8868\u4e2d\u5c55\u793a\u4e86 \u6307\u4ee4 \uff0c \u6570\u636e \uff0cCPU\u7684\u8fd0\u7b97\u903b\u8f91\u7b49\u5173\u952e\u5185\u5bb9\uff1b NOTE : \u4ece\u88681.4\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u8fd0\u7b97\u5668\u7684\u64cd\u4f5c\u6570\u9700\u8981\u901a\u8fc7 \u53d6\u6570\u6307\u4ee4 \u4ece\u5185\u5b58\u4e2d\u52a0\u8f7d\u5230 \u8fd0\u7b97\u5668 \u4e2d\uff1b\u88681.4\u8fd8\u5c55\u793a\u5904\u7406\uff0c\u8fd0\u7b97\u5668\u5728\u6267\u884c\u8fd0\u7b97\u6307\u4ee4\uff0c\u5982 \u4e58\u6cd5\u6307\u4ee4 \uff0c \u52a0\u6cd5\u6307\u4ee4 \u7b49\u7684\u65f6\u5019\uff0c\u4ea7\u751f\u7684\u8fd0\u7b97\u7ed3\u679c\u662f\u4fdd\u7559\u5728\u8fd0\u7b97\u5668\u4e2d\uff0c\u9700\u8981\u6267\u884c \u5b58\u6570\u6307\u4ee4 \u624d\u80fd\u591f\u5c06 \u8fd0\u7b97\u5668 \u4e2d\u7684\u6570\u636e\u5199\u5165\u5230\u5185\u5b58\u4e2d\uff1b\u8fd9\u5176\u5b9e\u975e\u5e38\u662f\u7b26\u5408 Load\u2013store architecture \u7684\u3002 2. \u6307\u4ee4\u7684\u5f62\u5f0f \u6bcf\u6761\u6307\u4ee4\u9700\u8981\u660e\u786e\u5730\u544a\u8bc9\u63a7\u5236\u5668\uff0c\u4ece\u5b58\u50a8\u5668\u7684\u54ea\u4e2a\u5355\u5143\u53d6\u6570\uff0c\u5e76\u8fdb\u884c\u4f55\u79cd\u64cd\u4f5c\uff1b\u8fd9\u6837\u4e00\u6765\uff0c\u53ef\u77e5\u6307\u4ee4\u7684\u5185\u5bb9\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u64cd\u4f5c\u7684\u6027\u8d28\u548c\u64cd\u4f5c\u6570\u7684\u5730\u5740\uff1b\u524d\u8005\u4e3a \u64cd\u4f5c\u7801 \uff0c\u540e\u8005\u4e3a \u5730\u5740\u7801 \uff1b \u64cd\u4f5c\u7801|\u5730\u5740\u7801 \u6307\u4ee4\u7684 \u64cd\u4f5c\u7801 \u548c \u5730\u5740\u7801 \u90fd\u53ef\u4ee5\u4f7f\u7528 \u4e8c\u8fdb\u5236\u4ee3\u7801 \u6765\u8fdb\u884c\u8868\u793a\uff0c\u8fd9\u5c31\u662f \u6307\u4ee4\u7684\u6570\u7801\u5316 \uff1b\u6307\u4ee4 \u6570\u7801\u5316 \u4ee5\u540e\uff0c\u5c31\u770b\u53ef\u4ee5\u548c\u6570\u636e\u4e00\u6837\u5b58\u5165\u5230 \u5b58\u50a8\u5668 \u4e2d( Stored-program computer )\uff1b\u5b58\u50a8\u5668\u7684\u4efb\u4f55\u4f4d\u7f6e\u65e2\u53ef\u4ee5\u5b58\u653e\u6570\u636e\u4e5f\u53ef\u4ee5\u5b58\u653e\u6307\u4ee4\uff0c\u4e0d\u8fc7\u4e00\u822c\u5c06\u6307\u4ee4\u548c\u6570\u636e\u5206\u5f00\u5b58\u653e\u3002 \u63a7\u5236\u5668 \u4f9d\u636e\u5b58\u50a8\u7684\u7a0b\u5e8f\u6765\u63a7\u5236\u5168\u673a\u534f\u8c03\u5730\u5b8c\u6210\u8ba1\u7b97\u4efb\u52a1\u53eb\u505a \u7a0b\u5e8f\u63a7\u5236 \u3002 \u6309\u7167 Von Neumann architecture \u7684\u601d\u60f3\uff0c\u6307\u4ee4\u548c\u6570\u636e\uff08\u5982\u679c\u4e0d\u6e05\u695a\u4e24\u8005\u7684\u5dee\u522b\uff0c\u53bb\u770b\u88681-4\uff09\u5b58\u653e\u5728\u540c\u4e00\u4e2a\u5b58\u50a8\u5668\u4e2d\uff0c \u63a7\u5236\u5668 \u6309\u7167stored program\u7684 \u5730\u5740\u987a\u5e8f \u8fdb\u884c\u6267\u884c\uff1b \u6309\u7167 Harvard architecture \u7684\u601d\u60f3\uff0c\u5c06\u6307\u4ee4\u548c\u6570\u636e\u5206\u522b\u5b58\u653e\u5728\u4e24\u4e2a\u5b58\u50a8\u5668\u4e2d\uff1b \u4e00\u53f0\u8ba1\u7b97\u673a\u901a\u5e38\u6709\u51e0\u5341\u79cd\u57fa\u672c \u6307\u4ee4 \uff0c\u4ece\u800c\u6784\u6210\u8be5\u8ba1\u7b97\u673a\u7684 \u6307\u4ee4\u7cfb\u7edf \u3002 \u6307\u4ee4\u7cfb\u7edf \u4e0d\u4ec5\u662f \u786c\u4ef6\u8bbe\u8ba1 \u7684\u4f9d\u636e\uff0c\u800c\u4e14\u662f \u8f6f\u4ef6\u8bbe\u8ba1 \u7684\u57fa\u7840\u3002\u56e0\u6b64 \u6307\u4ee4\u7cfb\u7edf \u662f\u8861\u91cf \u8ba1\u7b97\u673a\u6027\u80fd \u7684\u4e00\u4e2a\u91cd\u8981\u6307\u6807\u3002 3. \u63a7\u5236\u5668\u7684\u57fa\u672c\u4efb\u52a1 \u7531\u88681-4\u53ef\u77e5\uff0c\u8ba1\u7b97\u673a\u5728\u8fdb\u884c\u8ba1\u7b97\u7684\u65f6\u5019\uff0c \u6307\u4ee4 \u5fc5\u987b\u662f\u6309\u7167\u4e00\u5b9a\u7684 \u987a\u5e8f \u4e00\u6761\u63a5\u7740\u4e00\u6761\u7684\u8fdb\u884c\uff1b \u63a7\u5236\u5668 \u7684\u57fa\u672c\u4efb\u52a1\u5c31\u662f\u6309\u7167\u8ba1\u7b97\u673a\u7a0b\u5e8f\u6240\u6392\u7684\u6307\u4ee4\u5e8f\u5217\uff0c\u5148\u4ece \u5b58\u50a8\u5668 \u4e2d\u53d6\u51fa\u4e00\u6761\u6307\u4ee4\u653e\u5230 \u63a7\u5236\u5668 \u4e2d\uff0c\u5bf9\u8be5 \u6307\u4ee4 \u7684 \u64cd\u4f5c\u7801 \u7531 \u8bd1\u7801\u5668 \u8fdb\u884c\u5206\u6790\u5224\u65ad\uff0c\u7136\u540e\u6839\u636e \u6307\u4ee4\u6027\u8d28 \uff08\u5373\u8be5\u6307\u4ee4\u8981\u505a\u4ec0\u4e48\u8fd0\u7b97\uff09\uff0c\u6267\u884c\u8fd9\u6761\u6307\u4ee4\uff1b\u63a5\u7740\u4ece\u5b58\u50a8\u5668\u4e2d\u53d6\u51fa\u7b2c\u4e8c\u6761\u6307\u4ee4\uff0c\u518d\u6267\u884c\u7b2c\u4e8c\u6761\u6307\u4ee4\u3002\u4ee5\u6b64\u7c7b\u63a8\u3002 \u901a\u5e38\uff0c\u5c06\u53d6\u6307\u4ee4\u7684\u8fd9\u6bb5\u65f6\u95f4\u53eb\u505a \u53d6\u6307\u5468\u671f \uff0c\u800c\u628a\u6267\u884c\u6307\u4ee4\u7684\u4e00\u6bb5\u65f6\u95f4\u53eb\u505a \u6267\u884c\u5468\u671f \u3002\u56e0\u6b64\u63a7\u5236\u5668\u53cd\u590d\u4ea4\u66ff\u5730\u5904\u4e8e\u53d6\u6307\u5468\u671f\u548c\u6267\u884c\u5468\u671f\u4e4b\u4e2d\uff1b \u6bcf\u53d6\u51fa\u4e00\u6761\u6307\u4ee4\uff0c\u63a7\u5236\u5668\u4e2d\u7684 \u6307\u4ee4\u8ba1\u6570\u5668 \u5c31\u52a01\uff0c\u4ece\u800c\u4e3a\u4e0b\u4e00\u6761\u6307\u4ee4\u505a\u597d\u51c6\u5907\uff0c\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u6307\u4ee4\u5728\u5b58\u50a8\u5668\u4e2d\u662f\u987a\u5e8f\u5b58\u653e\u7684\u539f\u56e0\uff1b 4. \u6307\u4ee4\u6d41\u548c\u6570\u636e\u6d41 \u6211\u4eec\u4f7f\u7528bit\u6765\u4f5c\u4e3a\u8ba1\u7b97\u673a\u7684\u6700\u5c0f\u4fe1\u606f\u5355\u4f4d\u3002 \u5f53CPU\u5411\u5b58\u50a8\u5668\u9001\u5165\u6216\u8005\u4ece\u5b58\u50a8\u5668\u4e2d\u53d6\u51fa\u4fe1\u606f\u65f6\uff0c\u5f80\u5f80\u662f\u5b58\u53d6byte\uff08\u5b57\u8282\uff09\u548cWord\uff08\u5b57\uff09\u7b49\u8f83\u5927\u4fe1\u606f\u5355\u4f4d\uff0c\u800c\u4e0d\u662fbit\uff1b\u901a\u5e38\u5c06\u7ec4\u6210\u4e00\u4e2aWord\u7684\u4e8c\u8fdb\u5236\u4f4d\u6570\u53eb\u505a \u5b57\u957f \uff1b SUMMARY : \u8fd9\u5e94\u8be5\u662f\u6211\u4eec\u9700\u8981\u8fdb\u884c\u5730\u5740\u5bf9\u9f50\u7684\u539f\u56e0\u6240\u5728\uff1b SUMMARY : \u8fd9\u90e8\u5206\u5185\u5bb9\u57284.2.3 \u6307\u4ee4\u5b57\u957f\u5ea6 \u7ae0\u8282\u4e5f\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff1b \u7531\u4e8e\u8ba1\u7b97\u673a\u4f7f\u7528\u7684\u4fe1\u606f\u65e2\u6709\u6307\u4ee4\u53c8\u6709\u6570\u636e\uff0c\u6240\u4ee5 \u8ba1\u7b97\u673a\u5b57 \u65e2\u53ef\u4ee5\u4ee3\u8868 \u6307\u4ee4 \uff0c\u4e5f\u53ef\u4ee5\u4ee3\u8868 \u6570\u636e \uff1b\u5982\u679c\u67d0\u5b57\u4ee3\u8868\u7684\u662f\u8981\u5904\u7406\u7684\u6570\u636e\uff0c\u5219\u79f0\u4e3a \u6570\u636e\u5b57 \uff1b\u5982\u679c\u67d0\u5b57\u4e3a\u4e00\u6761\u6307\u4ee4\uff0c\u5219\u79f0\u4e3a \u6307\u4ee4\u5b57 \uff1b \u6211\u4eec\u770b\u5230\uff0c\u6307\u4ee4\u548c\u6570\u636e\u7edf\u7edf\u90fd\u5b58\u653e\u5728\u5185\u5b58\u4e2d\uff0c\u4ece\u5f62\u5f0f\u4e0a\u6765\u770b\uff0c\u5b83\u4eec\u90fd\u662f\u4e8c\u8fdb\u5236\u6570\u7801\uff0c\u4f3c\u4e4e\u5f88\u96be\u5206\u6e05\u695a\u54ea\u4e9b\u662f \u6307\u4ee4\u5b57 \uff0c\u54ea\u4e9b\u662f \u6570\u636e\u5b57 \uff1b\u90a3\u8fd9\u5c31\u5f15\u51fa\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a\u63a7\u5236\u5668\u662f\u5982\u4f55\u533a\u5206\u5f00\u54ea\u4e9b\u662f \u6307\u4ee4\u5b57 \uff0c\u54ea\u4e9b\u662f \u6570\u636e\u5b57 \u7684\uff1f\u7b54\u6848\u4e3a\uff1a \u53d6\u6307\u5468\u671f \u4e2d\uff0c\u4ece \u5185\u5b58 \u8bfb\u51fa\u7684 \u4fe1\u606f\u6d41 \u662f \u6307\u4ee4\u6d41 \uff0c\u5b83\u6d41\u5411 \u63a7\u5236\u5668 \uff1b \u6267\u884c\u5468\u671f \u4e2d\u4ece\u5185\u5b58\u4e2d\u8bfb\u51fa\u7684 \u4fe1\u606f\u6d41 \u4e3a \u6570\u636e\u6d41 \uff0c\u5b83\u7531\u5185\u5b58\u6d41\u5411 \u8fd0\u7b97\u5668 \uff1b\u663e\u7136\uff0c\u67d0\u4e9b\u6307\u4ee4\u8fdb\u884c\u8fc7\u7a0b\u4e2d\uff0c\u9700\u8981\u4e24\u6b21\u8bbf\u95ee\u5185\u5b58\uff0c\u4e00\u6b21\u662f\u53d6\u6307\u4ee4\uff0c\u53e6\u4e00\u6b21\u662f\u53d6\u6570\u636e\uff0c\u5982\u88681.4\u4e2d\u53d6\u6570\u3001\u4e58\u6570\u3001\u52a0\u6cd5\u3001\u51cf\u6cd5\u3001\u5b58\u6570\u6307\u4ee4\u5c31\u662f\u5982\u6b64\uff1b 1.3.5 \u9002\u914d\u5668\u4e0e\u8f93\u5165\u8f93\u51fa\u8bbe\u5907 \u8ba1\u7b97\u673a\u7cfb\u7edf\u4e2d\u5fc5\u987b\u6709 \u603b\u7ebf \uff0c \u7cfb\u7edf\u603b\u7ebf \u662f\u6784\u6210\u8ba1\u7b97\u673a\u7cfb\u7edf\u7684\u9aa8\u67b6\uff0c\u662f\u591a\u4e2a\u7cfb\u7edf\u90e8\u4ef6\u4e4b\u95f4\u8fdb\u884c\u6570\u636e\u4f20\u8f93\u7684\u516c\u5171\u901a\u8def\uff1b\u501f\u52a9 \u7cfb\u7edf\u603b\u7ebf \uff0c\u8ba1\u7b97\u673a\u5728\u7cfb\u7edf\u90e8\u4ef6\u4e4b\u95f4\u5b9e\u73b0\u4f20\u9001\u5730\u5740\u3001\u6570\u636e\u548c\u63a7\u5236\u4fe1\u606f\uff1b","title":"1.3-\u8ba1\u7b97\u673a\u786c\u4ef6"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/#13","text":"","title":"1.3\u8ba1\u7b97\u673a\u7684\u786c\u4ef6"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/#131","text":"\u4f7f\u7528\u6253\u7b97\u76d8\u6765\u8bf4\u660e\u8ba1\u7b97\u673a\u7684\u4e3b\u8981\u7ec4\u6210\u548c\u5de5\u4f5c\u539f\u7406\u3002\u7ed9\u5b9a\u4e00\u4e2a\u7b97\u76d8\u3001\u4e00\u5f20\u5e26\u6709\u6a2a\u683c\u7684\u7eb8\u3001\u4e00\u652f\u7b14\uff0c\u8981\u6c42\u8ba1\u7b97y=ax+b-c\u3002\u4e0b\u9762\u5c06\u89e3\u9898\u6b65\u9aa4\u8bb0\u5f55\u5728\u5e26\u6709\u6a2a\u683c\u7684\u7eb8\u5e26\u4e0a\uff1a \u88681.3\u89e3\u9898\u6b65\u9aa4\u548c\u6570\u636e\u8bb0\u5f55\u5728\u6a2a\u683c\u7eb8\u4e0a \u884c\u6570 \u89e3\u9898\u6b65\u9aa4\u548c\u6570\u636e \u8bf4\u660e 1 \u53d6\u6570 \uff089\uff09->\u7b97\u76d8 \uff089\uff09\u8868\u793a\u7b2c9\u884c\u7684\u6570a\uff0c\u4e0b\u540c 2 \u4e58\u6cd5 \uff0812\uff09->\u7b97\u76d8 \u5b8c\u6210 a*x \uff0c\u7ed3\u679c\u5728\u7b97\u76d8\u4e0a 3 \u52a0\u6cd5 \uff0810\uff09->\u7b97\u76d8 \u5b8c\u6210 a*x+b \uff0c\u7ed3\u679c\u5728\u7b97\u76d8\u4e0a 4 \u51cf\u6cd5 \uff0811\uff09->\u7b97\u76d8 \u5b8c\u6210 y=a*x+b-c \uff0c\u7ed3\u679c\u5728\u7b97\u76d8\u4e0a 5 \u5b58\u6570 y->13 \u7b97\u76d8\u4e0a\u7684y\u503c\u8bb0\u523013\u884c 6 \u8f93\u51fa \u5c06\u7b97\u76d8\u4e0a\u7684y\u503c\u5199\u51fa\u6765\u7ed9\u4eba\u770b 7 \u505c\u6b62 8 9 a \u6570\u636e 10 b \u6570\u636e 11 c \u6570\u636e 12 x \u6570\u636e 13 y \u6570\u636e \u5728\u7535\u5b50\u8ba1\u7b97\u673a\u4e2d\uff1a \u8fd0\u7b97\u5668 \u76f8\u5f53\u4e8e\u7b97\u76d8 \u5b58\u50a8\u5668 \u76f8\u5f53\u4e8e\u7eb8 \u63a7\u5236\u5668 \u76f8\u5f53\u4e8e\u4eba\u7684\u5927\u8111\uff08\u63a7\u5236\u7740\u6574\u4e2a\u8ba1\u7b97\u8fc7\u7a0b\uff09 |<--> \u5b58\u50a8\u5668 | \u7cfb |<--> \u8fd0\u7b97\u5668 \u7edf | \u603b |<--> \u63a7\u5236\u5668 \u7ebf | |<--> \u9002\u914d\u5668 | | | | \u8f93\u5165\u8bbe\u5907 \u8f93\u51fa\u8bbe\u5907 CPU = \u8fd0\u7b97\u5668 + \u63a7\u5236\u5668","title":"1.3.1 \u786c\u4ef6\u7ec4\u6210\u8981\u7d20"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/#132","text":"\u53c2\u89c1\uff1a ALU \u5b57\u957f\uff1a\u8fd0\u7b97\u5668\u7684\u957f\u5ea6","title":"1.3.2 \u8fd0\u7b97\u5668"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/#133","text":"\u53c2\u89c1\uff1a Computer memory","title":"1.3.3 \u5b58\u50a8\u5668"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/#134","text":"\u53c2\u89c1\uff1a Control unit \u63a7\u5236\u5668\u7684\u4efb\u52a1\u662f\u4ece\u5185\u5b58\u4e2d\u53d6\u51fa\u89e3\u9898\u6b65\u9aa4\u52a0\u4ee5\u5206\u6790\uff0c\u7136\u540e\u6267\u884c\u67d0\u79cd\u64cd\u4f5c\uff1b NOTE: \u8bfb\u53d6\u6307\u4ee4\u548c\u8bfb\u53d6\u6570\u636e\u90fd\u662f\u7531\u63a7\u5236\u5668\u6765\u5b8c\u6210\u7684\uff1b\u6240\u4ee5\u63a7\u5236\u5668\u9700\u8981\u4e86\u89e3\u6307\u4ee4\u7684\u683c\u5f0f","title":"1.3.4 \u63a7\u5236\u5668"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/#1","text":"\u88681.4\u8ba1\u7b97y=ax+b-c\u7684\u7a0b\u5e8f \u6307\u4ee4\u5730\u5740 \u64cd\u4f5c\u7801 \u5730\u5740\u7801 \u6307\u4ee4\u64cd\u4f5c\u5185\u5bb9 \u8bf4\u660e 1 \u53d6\u6570 9 (9) -> A \u5c06\u5b58\u50a8\u56689\u53f7\u5730\u5740\u7684\u6570\u8bfb\u5165\u5230\u8fd0\u7b97\u5668A 2 \u4e58\u6cd5 12 (A) * (12) -> A \u5b8c\u6210 a*x \uff0c\u7ed3\u679c\u4fdd\u7559\u7740\u8fd0\u7b97\u5668A 3 \u52a0\u6cd5 10 (A) + (10) -> A \u5b8c\u6210 a*x+b \uff0c\u7ed3\u679c\u4fdd\u7559\u7740\u8fd0\u7b97\u5668A 4 \u51cf\u6cd5 11 (A) - (11) -> A \u5b8c\u6210 a*x+b-c \uff0c\u7ed3\u679c\u4fdd\u7559\u7740\u8fd0\u7b97\u5668A 5 \u5b58\u6570 13 A->13 \u8fd0\u7b97\u5668A\u4e2d\u7684\u7ed3\u679cy\u9001\u5165\u5230\u5b58\u50a8\u566813\u53f7\u5730\u5740 6 \u6253\u5370 7 \u505c\u6b62 8 \u6570\u636e\u5730\u5740 \u6570\u636e \u8bf4\u660e 9 a 10 b 11 c 12 x 13 y \u88681.4\u662f\u4e00\u4e2a\u975e\u5e38\u597d\u7684\u4f8b\u5b50\uff0c\u8fd9\u4e2a\u8868\u4e2d\u5c55\u793a\u4e86 \u6307\u4ee4 \uff0c \u6570\u636e \uff0cCPU\u7684\u8fd0\u7b97\u903b\u8f91\u7b49\u5173\u952e\u5185\u5bb9\uff1b NOTE : \u4ece\u88681.4\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u8fd0\u7b97\u5668\u7684\u64cd\u4f5c\u6570\u9700\u8981\u901a\u8fc7 \u53d6\u6570\u6307\u4ee4 \u4ece\u5185\u5b58\u4e2d\u52a0\u8f7d\u5230 \u8fd0\u7b97\u5668 \u4e2d\uff1b\u88681.4\u8fd8\u5c55\u793a\u5904\u7406\uff0c\u8fd0\u7b97\u5668\u5728\u6267\u884c\u8fd0\u7b97\u6307\u4ee4\uff0c\u5982 \u4e58\u6cd5\u6307\u4ee4 \uff0c \u52a0\u6cd5\u6307\u4ee4 \u7b49\u7684\u65f6\u5019\uff0c\u4ea7\u751f\u7684\u8fd0\u7b97\u7ed3\u679c\u662f\u4fdd\u7559\u5728\u8fd0\u7b97\u5668\u4e2d\uff0c\u9700\u8981\u6267\u884c \u5b58\u6570\u6307\u4ee4 \u624d\u80fd\u591f\u5c06 \u8fd0\u7b97\u5668 \u4e2d\u7684\u6570\u636e\u5199\u5165\u5230\u5185\u5b58\u4e2d\uff1b\u8fd9\u5176\u5b9e\u975e\u5e38\u662f\u7b26\u5408 Load\u2013store architecture \u7684\u3002","title":"1. \u8ba1\u7b97\u7a0b\u5e8f"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/#2","text":"\u6bcf\u6761\u6307\u4ee4\u9700\u8981\u660e\u786e\u5730\u544a\u8bc9\u63a7\u5236\u5668\uff0c\u4ece\u5b58\u50a8\u5668\u7684\u54ea\u4e2a\u5355\u5143\u53d6\u6570\uff0c\u5e76\u8fdb\u884c\u4f55\u79cd\u64cd\u4f5c\uff1b\u8fd9\u6837\u4e00\u6765\uff0c\u53ef\u77e5\u6307\u4ee4\u7684\u5185\u5bb9\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u64cd\u4f5c\u7684\u6027\u8d28\u548c\u64cd\u4f5c\u6570\u7684\u5730\u5740\uff1b\u524d\u8005\u4e3a \u64cd\u4f5c\u7801 \uff0c\u540e\u8005\u4e3a \u5730\u5740\u7801 \uff1b \u64cd\u4f5c\u7801|\u5730\u5740\u7801 \u6307\u4ee4\u7684 \u64cd\u4f5c\u7801 \u548c \u5730\u5740\u7801 \u90fd\u53ef\u4ee5\u4f7f\u7528 \u4e8c\u8fdb\u5236\u4ee3\u7801 \u6765\u8fdb\u884c\u8868\u793a\uff0c\u8fd9\u5c31\u662f \u6307\u4ee4\u7684\u6570\u7801\u5316 \uff1b\u6307\u4ee4 \u6570\u7801\u5316 \u4ee5\u540e\uff0c\u5c31\u770b\u53ef\u4ee5\u548c\u6570\u636e\u4e00\u6837\u5b58\u5165\u5230 \u5b58\u50a8\u5668 \u4e2d( Stored-program computer )\uff1b\u5b58\u50a8\u5668\u7684\u4efb\u4f55\u4f4d\u7f6e\u65e2\u53ef\u4ee5\u5b58\u653e\u6570\u636e\u4e5f\u53ef\u4ee5\u5b58\u653e\u6307\u4ee4\uff0c\u4e0d\u8fc7\u4e00\u822c\u5c06\u6307\u4ee4\u548c\u6570\u636e\u5206\u5f00\u5b58\u653e\u3002 \u63a7\u5236\u5668 \u4f9d\u636e\u5b58\u50a8\u7684\u7a0b\u5e8f\u6765\u63a7\u5236\u5168\u673a\u534f\u8c03\u5730\u5b8c\u6210\u8ba1\u7b97\u4efb\u52a1\u53eb\u505a \u7a0b\u5e8f\u63a7\u5236 \u3002 \u6309\u7167 Von Neumann architecture \u7684\u601d\u60f3\uff0c\u6307\u4ee4\u548c\u6570\u636e\uff08\u5982\u679c\u4e0d\u6e05\u695a\u4e24\u8005\u7684\u5dee\u522b\uff0c\u53bb\u770b\u88681-4\uff09\u5b58\u653e\u5728\u540c\u4e00\u4e2a\u5b58\u50a8\u5668\u4e2d\uff0c \u63a7\u5236\u5668 \u6309\u7167stored program\u7684 \u5730\u5740\u987a\u5e8f \u8fdb\u884c\u6267\u884c\uff1b \u6309\u7167 Harvard architecture \u7684\u601d\u60f3\uff0c\u5c06\u6307\u4ee4\u548c\u6570\u636e\u5206\u522b\u5b58\u653e\u5728\u4e24\u4e2a\u5b58\u50a8\u5668\u4e2d\uff1b \u4e00\u53f0\u8ba1\u7b97\u673a\u901a\u5e38\u6709\u51e0\u5341\u79cd\u57fa\u672c \u6307\u4ee4 \uff0c\u4ece\u800c\u6784\u6210\u8be5\u8ba1\u7b97\u673a\u7684 \u6307\u4ee4\u7cfb\u7edf \u3002 \u6307\u4ee4\u7cfb\u7edf \u4e0d\u4ec5\u662f \u786c\u4ef6\u8bbe\u8ba1 \u7684\u4f9d\u636e\uff0c\u800c\u4e14\u662f \u8f6f\u4ef6\u8bbe\u8ba1 \u7684\u57fa\u7840\u3002\u56e0\u6b64 \u6307\u4ee4\u7cfb\u7edf \u662f\u8861\u91cf \u8ba1\u7b97\u673a\u6027\u80fd \u7684\u4e00\u4e2a\u91cd\u8981\u6307\u6807\u3002","title":"2. \u6307\u4ee4\u7684\u5f62\u5f0f"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/#3","text":"\u7531\u88681-4\u53ef\u77e5\uff0c\u8ba1\u7b97\u673a\u5728\u8fdb\u884c\u8ba1\u7b97\u7684\u65f6\u5019\uff0c \u6307\u4ee4 \u5fc5\u987b\u662f\u6309\u7167\u4e00\u5b9a\u7684 \u987a\u5e8f \u4e00\u6761\u63a5\u7740\u4e00\u6761\u7684\u8fdb\u884c\uff1b \u63a7\u5236\u5668 \u7684\u57fa\u672c\u4efb\u52a1\u5c31\u662f\u6309\u7167\u8ba1\u7b97\u673a\u7a0b\u5e8f\u6240\u6392\u7684\u6307\u4ee4\u5e8f\u5217\uff0c\u5148\u4ece \u5b58\u50a8\u5668 \u4e2d\u53d6\u51fa\u4e00\u6761\u6307\u4ee4\u653e\u5230 \u63a7\u5236\u5668 \u4e2d\uff0c\u5bf9\u8be5 \u6307\u4ee4 \u7684 \u64cd\u4f5c\u7801 \u7531 \u8bd1\u7801\u5668 \u8fdb\u884c\u5206\u6790\u5224\u65ad\uff0c\u7136\u540e\u6839\u636e \u6307\u4ee4\u6027\u8d28 \uff08\u5373\u8be5\u6307\u4ee4\u8981\u505a\u4ec0\u4e48\u8fd0\u7b97\uff09\uff0c\u6267\u884c\u8fd9\u6761\u6307\u4ee4\uff1b\u63a5\u7740\u4ece\u5b58\u50a8\u5668\u4e2d\u53d6\u51fa\u7b2c\u4e8c\u6761\u6307\u4ee4\uff0c\u518d\u6267\u884c\u7b2c\u4e8c\u6761\u6307\u4ee4\u3002\u4ee5\u6b64\u7c7b\u63a8\u3002 \u901a\u5e38\uff0c\u5c06\u53d6\u6307\u4ee4\u7684\u8fd9\u6bb5\u65f6\u95f4\u53eb\u505a \u53d6\u6307\u5468\u671f \uff0c\u800c\u628a\u6267\u884c\u6307\u4ee4\u7684\u4e00\u6bb5\u65f6\u95f4\u53eb\u505a \u6267\u884c\u5468\u671f \u3002\u56e0\u6b64\u63a7\u5236\u5668\u53cd\u590d\u4ea4\u66ff\u5730\u5904\u4e8e\u53d6\u6307\u5468\u671f\u548c\u6267\u884c\u5468\u671f\u4e4b\u4e2d\uff1b \u6bcf\u53d6\u51fa\u4e00\u6761\u6307\u4ee4\uff0c\u63a7\u5236\u5668\u4e2d\u7684 \u6307\u4ee4\u8ba1\u6570\u5668 \u5c31\u52a01\uff0c\u4ece\u800c\u4e3a\u4e0b\u4e00\u6761\u6307\u4ee4\u505a\u597d\u51c6\u5907\uff0c\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u6307\u4ee4\u5728\u5b58\u50a8\u5668\u4e2d\u662f\u987a\u5e8f\u5b58\u653e\u7684\u539f\u56e0\uff1b","title":"3. \u63a7\u5236\u5668\u7684\u57fa\u672c\u4efb\u52a1"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/#4","text":"\u6211\u4eec\u4f7f\u7528bit\u6765\u4f5c\u4e3a\u8ba1\u7b97\u673a\u7684\u6700\u5c0f\u4fe1\u606f\u5355\u4f4d\u3002 \u5f53CPU\u5411\u5b58\u50a8\u5668\u9001\u5165\u6216\u8005\u4ece\u5b58\u50a8\u5668\u4e2d\u53d6\u51fa\u4fe1\u606f\u65f6\uff0c\u5f80\u5f80\u662f\u5b58\u53d6byte\uff08\u5b57\u8282\uff09\u548cWord\uff08\u5b57\uff09\u7b49\u8f83\u5927\u4fe1\u606f\u5355\u4f4d\uff0c\u800c\u4e0d\u662fbit\uff1b\u901a\u5e38\u5c06\u7ec4\u6210\u4e00\u4e2aWord\u7684\u4e8c\u8fdb\u5236\u4f4d\u6570\u53eb\u505a \u5b57\u957f \uff1b SUMMARY : \u8fd9\u5e94\u8be5\u662f\u6211\u4eec\u9700\u8981\u8fdb\u884c\u5730\u5740\u5bf9\u9f50\u7684\u539f\u56e0\u6240\u5728\uff1b SUMMARY : \u8fd9\u90e8\u5206\u5185\u5bb9\u57284.2.3 \u6307\u4ee4\u5b57\u957f\u5ea6 \u7ae0\u8282\u4e5f\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff1b \u7531\u4e8e\u8ba1\u7b97\u673a\u4f7f\u7528\u7684\u4fe1\u606f\u65e2\u6709\u6307\u4ee4\u53c8\u6709\u6570\u636e\uff0c\u6240\u4ee5 \u8ba1\u7b97\u673a\u5b57 \u65e2\u53ef\u4ee5\u4ee3\u8868 \u6307\u4ee4 \uff0c\u4e5f\u53ef\u4ee5\u4ee3\u8868 \u6570\u636e \uff1b\u5982\u679c\u67d0\u5b57\u4ee3\u8868\u7684\u662f\u8981\u5904\u7406\u7684\u6570\u636e\uff0c\u5219\u79f0\u4e3a \u6570\u636e\u5b57 \uff1b\u5982\u679c\u67d0\u5b57\u4e3a\u4e00\u6761\u6307\u4ee4\uff0c\u5219\u79f0\u4e3a \u6307\u4ee4\u5b57 \uff1b \u6211\u4eec\u770b\u5230\uff0c\u6307\u4ee4\u548c\u6570\u636e\u7edf\u7edf\u90fd\u5b58\u653e\u5728\u5185\u5b58\u4e2d\uff0c\u4ece\u5f62\u5f0f\u4e0a\u6765\u770b\uff0c\u5b83\u4eec\u90fd\u662f\u4e8c\u8fdb\u5236\u6570\u7801\uff0c\u4f3c\u4e4e\u5f88\u96be\u5206\u6e05\u695a\u54ea\u4e9b\u662f \u6307\u4ee4\u5b57 \uff0c\u54ea\u4e9b\u662f \u6570\u636e\u5b57 \uff1b\u90a3\u8fd9\u5c31\u5f15\u51fa\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a\u63a7\u5236\u5668\u662f\u5982\u4f55\u533a\u5206\u5f00\u54ea\u4e9b\u662f \u6307\u4ee4\u5b57 \uff0c\u54ea\u4e9b\u662f \u6570\u636e\u5b57 \u7684\uff1f\u7b54\u6848\u4e3a\uff1a \u53d6\u6307\u5468\u671f \u4e2d\uff0c\u4ece \u5185\u5b58 \u8bfb\u51fa\u7684 \u4fe1\u606f\u6d41 \u662f \u6307\u4ee4\u6d41 \uff0c\u5b83\u6d41\u5411 \u63a7\u5236\u5668 \uff1b \u6267\u884c\u5468\u671f \u4e2d\u4ece\u5185\u5b58\u4e2d\u8bfb\u51fa\u7684 \u4fe1\u606f\u6d41 \u4e3a \u6570\u636e\u6d41 \uff0c\u5b83\u7531\u5185\u5b58\u6d41\u5411 \u8fd0\u7b97\u5668 \uff1b\u663e\u7136\uff0c\u67d0\u4e9b\u6307\u4ee4\u8fdb\u884c\u8fc7\u7a0b\u4e2d\uff0c\u9700\u8981\u4e24\u6b21\u8bbf\u95ee\u5185\u5b58\uff0c\u4e00\u6b21\u662f\u53d6\u6307\u4ee4\uff0c\u53e6\u4e00\u6b21\u662f\u53d6\u6570\u636e\uff0c\u5982\u88681.4\u4e2d\u53d6\u6570\u3001\u4e58\u6570\u3001\u52a0\u6cd5\u3001\u51cf\u6cd5\u3001\u5b58\u6570\u6307\u4ee4\u5c31\u662f\u5982\u6b64\uff1b","title":"4. \u6307\u4ee4\u6d41\u548c\u6570\u636e\u6d41"},{"location":"Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e/\u7b2c\u4e00\u7ae0-\u8ba1\u7b97\u673a\u7cfb\u7edf\u6982\u8ff0/1.3-\u8ba1\u7b97\u673a\u786c\u4ef6/#135","text":"\u8ba1\u7b97\u673a\u7cfb\u7edf\u4e2d\u5fc5\u987b\u6709 \u603b\u7ebf \uff0c \u7cfb\u7edf\u603b\u7ebf \u662f\u6784\u6210\u8ba1\u7b97\u673a\u7cfb\u7edf\u7684\u9aa8\u67b6\uff0c\u662f\u591a\u4e2a\u7cfb\u7edf\u90e8\u4ef6\u4e4b\u95f4\u8fdb\u884c\u6570\u636e\u4f20\u8f93\u7684\u516c\u5171\u901a\u8def\uff1b\u501f\u52a9 \u7cfb\u7edf\u603b\u7ebf \uff0c\u8ba1\u7b97\u673a\u5728\u7cfb\u7edf\u90e8\u4ef6\u4e4b\u95f4\u5b9e\u73b0\u4f20\u9001\u5730\u5740\u3001\u6570\u636e\u548c\u63a7\u5236\u4fe1\u606f\uff1b","title":"1.3.5 \u9002\u914d\u5668\u4e0e\u8f93\u5165\u8f93\u51fa\u8bbe\u5907"},{"location":"CPU/CPU\u7684\u65f6\u5e8f/","text":"\u9996\u5148\uff0cCPU\u6709 Clock generator \uff0c\u5b83\u4ea7\u751f Clock signal \uff0c\u5b83\u4ea7\u751fsignal\u7684\u9891\u7387\u79f0\u4e3a Clock rate \uff0cCPU\u7684\u63a7\u5236\u5355\u5143\u6709 Instruction cycle \uff0c\u5b83\u7684\u6027\u80fd\u5ea6\u91cf\u4e3a Cycles per instruction \u3002","title":"CPU\u7684\u65f6\u5e8f"},{"location":"CPU/Central-processing-unit/","text":"Central processing unit","title":"Central-processing-unit"},{"location":"CPU/Central-processing-unit/#central-processing-unit","text":"","title":"Central processing unit"},{"location":"CPU/Instruction-cycle/","text":"Instruction cycle","title":"Instruction-cycle"},{"location":"CPU/Instruction-cycle/#instruction-cycle","text":"","title":"Instruction cycle"},{"location":"CPU/Processor(computing)/","text":"Processor (computing) In computing , a processor or processing unit is an electronic circuit which performs operations on some external data source, usually memory or some other data stream. The term is frequently used to refer to the central processor ( central processing unit ) in a system, but typical computer systems (especially SoCs ) combine a number of specialised \"processors\". Examples CPU \u2013 central processing unit If designed conforming to the von Neumann architecture , it contains at least a control unit (CU), arithmetic logic unit (ALU) and processor registers . In some contexts, the ALU and registers are called the processing unit . GPU \u2013 graphics processing unit VPU \u2013 vision processing unit TPU \u2013 tensor processing unit NPU \u2013 neural processing unit PPU \u2013 physics processing unit DSP \u2013 digital signal processor ISP \u2013 image signal processor SPU or SPE \u2013 synergistic processing element in the Cell microprocessor FPGA \u2013 field-programmable gate array sound chip","title":"Processor(computing)"},{"location":"CPU/Processor(computing)/#processor-computing","text":"In computing , a processor or processing unit is an electronic circuit which performs operations on some external data source, usually memory or some other data stream. The term is frequently used to refer to the central processor ( central processing unit ) in a system, but typical computer systems (especially SoCs ) combine a number of specialised \"processors\".","title":"Processor (computing)"},{"location":"CPU/Processor(computing)/#examples","text":"CPU \u2013 central processing unit If designed conforming to the von Neumann architecture , it contains at least a control unit (CU), arithmetic logic unit (ALU) and processor registers . In some contexts, the ALU and registers are called the processing unit . GPU \u2013 graphics processing unit VPU \u2013 vision processing unit TPU \u2013 tensor processing unit NPU \u2013 neural processing unit PPU \u2013 physics processing unit DSP \u2013 digital signal processor ISP \u2013 image signal processor SPU or SPE \u2013 synergistic processing element in the Cell microprocessor FPGA \u2013 field-programmable gate array sound chip","title":"Examples"},{"location":"CPU/Assembly-language/Assembly-language/","text":"","title":"Assembly-language"},{"location":"CPU/Components/Control-unit/","text":"Control unit","title":"Control-unit"},{"location":"CPU/Components/Control-unit/#control-unit","text":"","title":"Control unit"},{"location":"CPU/Components/Register/Program-counter/","text":"Program counter \u8fd9\u4e2a\u5bc4\u5b58\u5668\u975e\u5e38\u91cd\u8981\uff0c\u5b83\u544a\u8bc9CPU\u53bb\u6267\u884c\u54ea\u4e00\u6761\u6307\u4ee4\u3002\u6240\u6709\u5bf9 control flow \u7684\u64cd\u4f5c\u7684\u6307\u4ee4\u6700\u7ec8\u90fd\u662f\u901a\u8fc7\u64cd\u4f5c\u8fd9\u4e2a\u5bc4\u5b58\u5668\u7684\u503c\u6765\u5b9e\u73b0\u7684\u3002 Program counter \u6240\u6307\u5411\u7684\u80af\u5b9a\u662fcode area\uff0c Program counter \u76f8\u5f53\u4e8enext pointer\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u5b83\u662f\u81ea\u52a01\u7684\uff0c\u9664\u975e\u901a\u8fc7 JMP (x86 instruction) \u7b49\u6307\u4ee4\u6765\u663e\u793a\u66f4\u6539\u5b83\u7684\u503c\u3002","title":"Program-counter"},{"location":"CPU/Components/Register/Program-counter/#program-counter","text":"\u8fd9\u4e2a\u5bc4\u5b58\u5668\u975e\u5e38\u91cd\u8981\uff0c\u5b83\u544a\u8bc9CPU\u53bb\u6267\u884c\u54ea\u4e00\u6761\u6307\u4ee4\u3002\u6240\u6709\u5bf9 control flow \u7684\u64cd\u4f5c\u7684\u6307\u4ee4\u6700\u7ec8\u90fd\u662f\u901a\u8fc7\u64cd\u4f5c\u8fd9\u4e2a\u5bc4\u5b58\u5668\u7684\u503c\u6765\u5b9e\u73b0\u7684\u3002 Program counter \u6240\u6307\u5411\u7684\u80af\u5b9a\u662fcode area\uff0c Program counter \u76f8\u5f53\u4e8enext pointer\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u5b83\u662f\u81ea\u52a01\u7684\uff0c\u9664\u975e\u901a\u8fc7 JMP (x86 instruction) \u7b49\u6307\u4ee4\u6765\u663e\u793a\u66f4\u6539\u5b83\u7684\u503c\u3002","title":"Program counter"},{"location":"CPU/Components/Register/Stack-register/","text":"Stack register A stack register is a computer central processor register whose purpose is to keep track of a call stack . On an accumulator-based architecture machine, this may be a dedicated register such as SP on an Intel x86 machine. Stack registers in x86 In 8086 , the main stack register is called stack pointer - SP. The stack segment register (SS) is usually used to store information about the memory segment that stores the call stack of currently executed program. SP points to current stack top . By default, the stack grows downward in memory, so newer values are placed at lower memory addresses. To push a value to the stack, the PUSH instruction is used. To pop a value from the stack, the POP instruction is used. NOTE: \u5bf9\u4e8e 8086 \uff0c SP\u548cSS\u9700\u8981\u4e00\u8d77\u624d\u80fd\u591f\u5de5\u4f5c\u3002 Example : Assuming that SS = 1000h and SP = 0xF820. This means that current stack top is the physical address 0x1F820 (this is due to memory segmentation in 8086 ). The next two machine instructions of the program are: PUSH AX PUSH BX These first instruction shall push the value stored in AX (16-bit register) to the stack. This is done by subtracting a value of 2 (2 bytes) from SP. The new value of SP becomes 0xF81E. The CPU then copies the value of AX to the memory word whose physical address is 0x1F81E. When \"PUSH BX\" is executed, SP is set to 0xF81C and BX is copied to 0x1F81C. NOTE: \u4e0a\u9762\u63cf\u8ff0\u7684\u8fc7\u7a0b\u5c31\u76f8\u5f53\u4e8e\u51fd\u6570\u5728\u6267\u884c\u7684\u65f6\u5019\uff0c\u7ed9\u81ea\u52a8\u53d8\u91cf\u5206\u914d\u5185\u5b58\u7a7a\u95f4\u3002 This illustrates how PUSH works. Usually, the running program pushes registers to the stack to make use of the registers for other purposes, like to call a routine that may change the current values of registers. To restore the values stored at the stack, the program shall contain machine instructions like this: POP BX POP AX POP BX copies the word at 0x1F81C (which is the old value of BX) to BX, then increases SP by 2. SP now is 0xF81E. POP AX copies the word at 0x1F81E to AX, then sets SP to 0xF820. NOTE : The program above pops BX first, that's because it was pushed last. NOTE : In 8086, PUSH & POP instructions can only work with 16-bit elements.","title":"Stack-register"},{"location":"CPU/Components/Register/Stack-register/#stack-register","text":"A stack register is a computer central processor register whose purpose is to keep track of a call stack . On an accumulator-based architecture machine, this may be a dedicated register such as SP on an Intel x86 machine.","title":"Stack register"},{"location":"CPU/Components/Register/Stack-register/#stack-registers-in-x86","text":"In 8086 , the main stack register is called stack pointer - SP. The stack segment register (SS) is usually used to store information about the memory segment that stores the call stack of currently executed program. SP points to current stack top . By default, the stack grows downward in memory, so newer values are placed at lower memory addresses. To push a value to the stack, the PUSH instruction is used. To pop a value from the stack, the POP instruction is used. NOTE: \u5bf9\u4e8e 8086 \uff0c SP\u548cSS\u9700\u8981\u4e00\u8d77\u624d\u80fd\u591f\u5de5\u4f5c\u3002 Example : Assuming that SS = 1000h and SP = 0xF820. This means that current stack top is the physical address 0x1F820 (this is due to memory segmentation in 8086 ). The next two machine instructions of the program are: PUSH AX PUSH BX These first instruction shall push the value stored in AX (16-bit register) to the stack. This is done by subtracting a value of 2 (2 bytes) from SP. The new value of SP becomes 0xF81E. The CPU then copies the value of AX to the memory word whose physical address is 0x1F81E. When \"PUSH BX\" is executed, SP is set to 0xF81C and BX is copied to 0x1F81C. NOTE: \u4e0a\u9762\u63cf\u8ff0\u7684\u8fc7\u7a0b\u5c31\u76f8\u5f53\u4e8e\u51fd\u6570\u5728\u6267\u884c\u7684\u65f6\u5019\uff0c\u7ed9\u81ea\u52a8\u53d8\u91cf\u5206\u914d\u5185\u5b58\u7a7a\u95f4\u3002 This illustrates how PUSH works. Usually, the running program pushes registers to the stack to make use of the registers for other purposes, like to call a routine that may change the current values of registers. To restore the values stored at the stack, the program shall contain machine instructions like this: POP BX POP AX POP BX copies the word at 0x1F81C (which is the old value of BX) to BX, then increases SP by 2. SP now is 0xF81E. POP AX copies the word at 0x1F81E to AX, then sets SP to 0xF820. NOTE : The program above pops BX first, that's because it was pushed last. NOTE : In 8086, PUSH & POP instructions can only work with 16-bit elements.","title":"Stack registers in x86"},{"location":"CPU/Instruction-set-architectures/Instruction-set-architecture/","text":"Instruction set architecture An instruction set architecture ( ISA ) is an abstract model of a computer . It is also referred to as architecture or computer architecture . A realization of an ISA is called an implementation . An ISA permits multiple implementations that may vary in performance , physical size, and monetary cost (among other things); because the ISA serves as the interface between software and hardware . Software that has been written for an ISA can run on different implementations of the same ISA. This has enabled binary compatibility between different generations of computers to be easily achieved, and the development of computer families . Both of these developments have helped to lower the cost of computers and to increase their applicability. For these reasons, the ISA is one of the most important abstractions in computing today. NOTE: \u8fd9\u6bb5\u8bdd\u5728\u300a\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-4.1-\u6307\u4ee4\u7cfb\u7edf\u7684\u53d1\u5c55\u548c\u6027\u80fd\u8981\u6c42\u300b\u4e2d\u4e5f\u6709\u63d0\u53ca\u3002ISA\u548c \u7cfb\u5217\u8ba1\u7b97\u673a \u7684\u6982\u5ff5\u5bc6\u5207\u76f8\u5173\u3002 An ISA defines everything a machine language programmer needs to know in order to program a computer. What an ISA defines differs between ISAs; in general, ISAs define the supported data types , what state there is (such as the main memory and registers ) and their semantics (such as the memory consistency and addressing modes ), the instruction set (the set of machine instructions that comprises a computer's machine language), and the input/output model. An ISA specifies the behavior of machine code running on implementations of that ISA in a fashion that does not depend on the characteristics of that implementation, providing binary compatibility between implementations. This enables multiple implementations of an ISA that differ in performance , physical size, and monetary cost (among other things), but that are capable of running the same machine code, so that a lower-performance, lower-cost machine can be replaced with a higher-cost, higher-performance machine without having to replace software. It also enables the evolution of the microarchitectures of the implementations of that ISA, so that a newer, higher-performance implementation of an ISA can run software that runs on previous generations of implementations. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u6240\u63cf\u8ff0\u7684\u5176\u5b9e\u662f\u5206\u79bb\u62bd\u8c61\u4e0e\u5b9e\u73b0\u5e26\u6765\u7684\u597d\u5904\u3002 If an operating system maintains a standard and compatible application binary interface (ABI) for a particular ISA, machine code for that ISA and operating system will run on future implementations of that ISA and newer versions of that operating system. However, if an ISA supports running multiple operating systems, it does not guarantee that machine code for one operating system will run on another operating system, unless the first operating system supports running machine code built for the other operating system. An ISA can be extended by adding instructions or other capabilities, or adding support for larger addresses and data values; an implementation of the extended ISA will still be able to execute machine code for versions of the ISA without those extensions. Machine code using those extensions will only run on implementations that support those extensions. The binary compatibility that they provide make ISAs one of the most fundamental abstractions in computing . Example \u4e0b\u9762\u7f57\u5217\u4e86\u4e00\u4e9b\u6bd4\u8f83\u5e38\u89c1\u7684ISA: x86 ARM MIPS Power ISA SPARC Itanium Classification of ISAs complex instruction set computer (CISC) reduced instruction set computer (RISC) Instructions Machine language is built up from discrete statements or instructions . On the processing architecture, a given instruction may specify: particular registers (for arithmetic, addressing, or control functions) particular memory locations (or offsets to them) particular addressing modes (used to interpret the operands) More complex operations are built up by combining these simple instructions, which are executed sequentially, or as otherwise directed by control flow instructions. Instruction types Data handling and memory operations Arithmetic and logic operations Control flow operations Coprocessor instructions","title":"Instruction-set-architecture"},{"location":"CPU/Instruction-set-architectures/Instruction-set-architecture/#instruction-set-architecture","text":"An instruction set architecture ( ISA ) is an abstract model of a computer . It is also referred to as architecture or computer architecture . A realization of an ISA is called an implementation . An ISA permits multiple implementations that may vary in performance , physical size, and monetary cost (among other things); because the ISA serves as the interface between software and hardware . Software that has been written for an ISA can run on different implementations of the same ISA. This has enabled binary compatibility between different generations of computers to be easily achieved, and the development of computer families . Both of these developments have helped to lower the cost of computers and to increase their applicability. For these reasons, the ISA is one of the most important abstractions in computing today. NOTE: \u8fd9\u6bb5\u8bdd\u5728\u300a\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-4.1-\u6307\u4ee4\u7cfb\u7edf\u7684\u53d1\u5c55\u548c\u6027\u80fd\u8981\u6c42\u300b\u4e2d\u4e5f\u6709\u63d0\u53ca\u3002ISA\u548c \u7cfb\u5217\u8ba1\u7b97\u673a \u7684\u6982\u5ff5\u5bc6\u5207\u76f8\u5173\u3002 An ISA defines everything a machine language programmer needs to know in order to program a computer. What an ISA defines differs between ISAs; in general, ISAs define the supported data types , what state there is (such as the main memory and registers ) and their semantics (such as the memory consistency and addressing modes ), the instruction set (the set of machine instructions that comprises a computer's machine language), and the input/output model. An ISA specifies the behavior of machine code running on implementations of that ISA in a fashion that does not depend on the characteristics of that implementation, providing binary compatibility between implementations. This enables multiple implementations of an ISA that differ in performance , physical size, and monetary cost (among other things), but that are capable of running the same machine code, so that a lower-performance, lower-cost machine can be replaced with a higher-cost, higher-performance machine without having to replace software. It also enables the evolution of the microarchitectures of the implementations of that ISA, so that a newer, higher-performance implementation of an ISA can run software that runs on previous generations of implementations. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u6240\u63cf\u8ff0\u7684\u5176\u5b9e\u662f\u5206\u79bb\u62bd\u8c61\u4e0e\u5b9e\u73b0\u5e26\u6765\u7684\u597d\u5904\u3002 If an operating system maintains a standard and compatible application binary interface (ABI) for a particular ISA, machine code for that ISA and operating system will run on future implementations of that ISA and newer versions of that operating system. However, if an ISA supports running multiple operating systems, it does not guarantee that machine code for one operating system will run on another operating system, unless the first operating system supports running machine code built for the other operating system. An ISA can be extended by adding instructions or other capabilities, or adding support for larger addresses and data values; an implementation of the extended ISA will still be able to execute machine code for versions of the ISA without those extensions. Machine code using those extensions will only run on implementations that support those extensions. The binary compatibility that they provide make ISAs one of the most fundamental abstractions in computing .","title":"Instruction set architecture"},{"location":"CPU/Instruction-set-architectures/Instruction-set-architecture/#example","text":"\u4e0b\u9762\u7f57\u5217\u4e86\u4e00\u4e9b\u6bd4\u8f83\u5e38\u89c1\u7684ISA: x86 ARM MIPS Power ISA SPARC Itanium","title":"Example"},{"location":"CPU/Instruction-set-architectures/Instruction-set-architecture/#classification-of-isas","text":"complex instruction set computer (CISC) reduced instruction set computer (RISC)","title":"Classification of ISAs"},{"location":"CPU/Instruction-set-architectures/Instruction-set-architecture/#instructions","text":"Machine language is built up from discrete statements or instructions . On the processing architecture, a given instruction may specify: particular registers (for arithmetic, addressing, or control functions) particular memory locations (or offsets to them) particular addressing modes (used to interpret the operands) More complex operations are built up by combining these simple instructions, which are executed sequentially, or as otherwise directed by control flow instructions.","title":"Instructions"},{"location":"CPU/Instruction-set-architectures/Instruction-set-architecture/#instruction-types","text":"","title":"Instruction types"},{"location":"CPU/Instruction-set-architectures/Instruction-set-architecture/#data-handling-and-memory-operations","text":"","title":"Data handling and memory operations"},{"location":"CPU/Instruction-set-architectures/Instruction-set-architecture/#arithmetic-and-logic-operations","text":"","title":"Arithmetic and logic operations"},{"location":"CPU/Instruction-set-architectures/Instruction-set-architecture/#control-flow-operations","text":"","title":"Control flow operations"},{"location":"CPU/Instruction-set-architectures/Instruction-set-architecture/#coprocessor-instructions","text":"","title":"Coprocessor instructions"},{"location":"CPU/Instruction-set-architectures/Machine-code/","text":"Machine code","title":"Machine-code"},{"location":"CPU/Instruction-set-architectures/Machine-code/#machine-code","text":"","title":"Machine code"},{"location":"CPU/Intel/","text":"Intel Resource & Design Center Intel 8086","title":"Introduction"},{"location":"CPU/Intel/#intel-resource-design-center","text":"","title":"Intel Resource &amp; Design Center"},{"location":"CPU/Intel/#intel-8086","text":"","title":"Intel 8086"},{"location":"CPU/Intel/X86-instruction/","text":"\u5173\u4e8e\u672c\u7ae0 x86 \u662f\u6bd4\u8f83\u5e38\u89c1\u7684 instruction set architecture \uff0c\u672c\u7ae0\u6574\u7406\u5b83\u7684\u76f8\u5173\u77e5\u8bc6\u3002 x86 Assembly Guide \u975e\u5e38\u68d2\u7684\u6587\u7ae0\uff0c\u9002\u5408\u5165\u95e8\u3002 Assembly Language Tutorial \uff0c\u6bd4\u8f83\u5168\u9762\u3002","title":"Introduction"},{"location":"CPU/Intel/X86-instruction/#_1","text":"x86 \u662f\u6bd4\u8f83\u5e38\u89c1\u7684 instruction set architecture \uff0c\u672c\u7ae0\u6574\u7406\u5b83\u7684\u76f8\u5173\u77e5\u8bc6\u3002 x86 Assembly Guide \u975e\u5e38\u68d2\u7684\u6587\u7ae0\uff0c\u9002\u5408\u5165\u95e8\u3002 Assembly Language Tutorial \uff0c\u6bd4\u8f83\u5168\u9762\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"CPU/Intel/X86-instruction/INT/","text":"INT (x86 instruction)","title":"INT"},{"location":"CPU/Intel/X86-instruction/INT/#int-x86-instruction","text":"","title":"INT (x86 instruction)"},{"location":"CPU/Intel/X86-instruction/Book-X86-assembly/","text":"x86 Assembly \u8fd9\u672c\u4e66\u8fd8\u6709\u4e00\u4e2a\u59ca\u59b9\u7bc7\uff1a x86 Disassembly \u3002","title":"Introduction"},{"location":"CPU/Intel/X86-instruction/Book-X86-assembly/#x86-assembly","text":"\u8fd9\u672c\u4e66\u8fd8\u6709\u4e00\u4e2a\u59ca\u59b9\u7bc7\uff1a x86 Disassembly \u3002","title":"x86 Assembly"},{"location":"CPU/Memory-access/","text":"\u5173\u4e8e\u672c\u7ae0 \u8bb0\u5f97\u5927\u5b66\u65f6\u5728\u5b66\u4e60\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u8bfe\u7a0b\u7684\u65f6\u5019\uff0c\u8001\u5e08\u63d0\u51fa\u8fc7\u91cd\u8981\u7684\u89c2\u70b9\uff1a \u201c\u9650\u5236CPU\u901f\u5ea6\u7684\u662f\u4ece\u5185\u5b58\u4e2d\u8bfb\u5199\u6570\u636e\u201d \u610f\u601d\u662fCPU\u7684ALU\u7684\u8fd0\u7b97\u901f\u5ea6\u662f\u975e\u5e38\u5feb\u7684\uff0c\u76f8\u6bd4\u4e4b\u4e0b\u4ece\u5185\u5b58\u4e2d\u8bfb\u53d6\u662f\u6bd4\u8f83\u7f13\u6162\u7684\uff0c\u6240\u4ee5ALU\u5e38\u5e38\u9700\u8981\u7b49\u5f85\uff0c\u8fd9\u5e94\u8be5\u662f\u5f53\u4ee3CPU\u8bbe\u8ba1\u65f6\u9700\u8981\u8003\u8651\u7684\u4e00\u4e2a\u77db\u76fe\u6240\u5728\uff0c\u5404\u79cd\u7f13\u89e3\u8fd9\u4e2a\u77db\u76fe\u7684\u6280\u672f\u4e0d\u65ad\u51fa\u73b0\uff0c\u6bd4\u5982 \u5728Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e\u76845.1.3CPU\u4e2d\u7684\u4e3b\u8981\u5bc4\u5b58\u5668\u7ae0\u8282\u4e2d\u6240\u63cf\u8ff0\u7684 \u6570\u636e\u7f13\u51b2\u5bc4\u5b58\u5668\uff08DR\uff09 \u7684\u4f5c\u7528\uff1a\u8865\u507fCPU\u548c\u5185\u5b58\u3001\u5916\u56f4\u8bbe\u5907\u4e4b\u95f4\u5728\u64cd\u4f5c\u901f\u5ea6\u4e0a\u7684\u5dee\u522b\u3002 \u672c\u7ae0\u4e3b\u8981\u4ecb\u7ecdCPU\u8bbf\u95eememory\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u8bfb\u8005\u8bb0\u4f4f\u4e0a\u9762\u7684\u8fd9\u4e2a\u89c2\u70b9\uff0c\u5e94\u8be5\u80fd\u591f\u6709\u52a9\u4e8e\u7406\u89e3\u4f7f\u7528\u4e00\u4e9b\u6280\u672f\u7684\u76ee\u7684\u6240\u5728\u3002","title":"Introduction"},{"location":"CPU/Memory-access/#_1","text":"\u8bb0\u5f97\u5927\u5b66\u65f6\u5728\u5b66\u4e60\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u8bfe\u7a0b\u7684\u65f6\u5019\uff0c\u8001\u5e08\u63d0\u51fa\u8fc7\u91cd\u8981\u7684\u89c2\u70b9\uff1a \u201c\u9650\u5236CPU\u901f\u5ea6\u7684\u662f\u4ece\u5185\u5b58\u4e2d\u8bfb\u5199\u6570\u636e\u201d \u610f\u601d\u662fCPU\u7684ALU\u7684\u8fd0\u7b97\u901f\u5ea6\u662f\u975e\u5e38\u5feb\u7684\uff0c\u76f8\u6bd4\u4e4b\u4e0b\u4ece\u5185\u5b58\u4e2d\u8bfb\u53d6\u662f\u6bd4\u8f83\u7f13\u6162\u7684\uff0c\u6240\u4ee5ALU\u5e38\u5e38\u9700\u8981\u7b49\u5f85\uff0c\u8fd9\u5e94\u8be5\u662f\u5f53\u4ee3CPU\u8bbe\u8ba1\u65f6\u9700\u8981\u8003\u8651\u7684\u4e00\u4e2a\u77db\u76fe\u6240\u5728\uff0c\u5404\u79cd\u7f13\u89e3\u8fd9\u4e2a\u77db\u76fe\u7684\u6280\u672f\u4e0d\u65ad\u51fa\u73b0\uff0c\u6bd4\u5982 \u5728Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e\u76845.1.3CPU\u4e2d\u7684\u4e3b\u8981\u5bc4\u5b58\u5668\u7ae0\u8282\u4e2d\u6240\u63cf\u8ff0\u7684 \u6570\u636e\u7f13\u51b2\u5bc4\u5b58\u5668\uff08DR\uff09 \u7684\u4f5c\u7528\uff1a\u8865\u507fCPU\u548c\u5185\u5b58\u3001\u5916\u56f4\u8bbe\u5907\u4e4b\u95f4\u5728\u64cd\u4f5c\u901f\u5ea6\u4e0a\u7684\u5dee\u522b\u3002 \u672c\u7ae0\u4e3b\u8981\u4ecb\u7ecdCPU\u8bbf\u95eememory\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u8bfb\u8005\u8bb0\u4f4f\u4e0a\u9762\u7684\u8fd9\u4e2a\u89c2\u70b9\uff0c\u5e94\u8be5\u80fd\u591f\u6709\u52a9\u4e8e\u7406\u89e3\u4f7f\u7528\u4e00\u4e9b\u6280\u672f\u7684\u76ee\u7684\u6240\u5728\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"CPU/Memory-access/Memory\u2013access/","text":"Memory access processor\u548cmemory\u4e4b\u95f4\u7684\u6570\u636e\u4f20\u8f93\u662fprocessor\u7684\u4e3b\u8981\u6d3b\u52a8\u4e4b\u4e00\uff0c\u672c\u7ae0\u4e3b\u8981\u5bf9\u4e0e\u6b64\u76f8\u5173\u7684\u5185\u5bb9\u8fdb\u884c\u6574\u7406\uff0c\u4e0b\u9762\u662f\u6d89\u53ca\u5230\u7684\u4e00\u4e9b\u5185\u5bb9\u3002 Memory\u2013processor transfer When the processor reads from the memory subsystem into a register or writes a register's value to memory, the amount of data transferred is often a word . Historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments. In simple memory subsystems, the word is transferred over the memory data bus , which typically has a width of a word or half-word. In memory subsystems that use caches , the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used. \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7ed9\u51fa\u4e86Memory\u2013processor transfer\u7684\u4e00\u4e2a\u7b80\u5355\u6a21\u578b\uff0c\u8fd9\u5176\u4e2d\u4f1a\u6d89\u53ca\u4e00\u7cfb\u5217\u95ee\u9898\uff0c\u9700\u8981\u8fdb\u884c\u6df1\u5165\u5206\u6790\uff0c\u672c\u7ae0\u540e\u7eed\u7ae0\u8282\u4f1a\u5bf9\u6b64\u8fdb\u884c\u5c55\u5f00\u3002 Register memory architecture Load\u2013store architecture","title":"Memory\u2013access"},{"location":"CPU/Memory-access/Memory\u2013access/#memory-access","text":"processor\u548cmemory\u4e4b\u95f4\u7684\u6570\u636e\u4f20\u8f93\u662fprocessor\u7684\u4e3b\u8981\u6d3b\u52a8\u4e4b\u4e00\uff0c\u672c\u7ae0\u4e3b\u8981\u5bf9\u4e0e\u6b64\u76f8\u5173\u7684\u5185\u5bb9\u8fdb\u884c\u6574\u7406\uff0c\u4e0b\u9762\u662f\u6d89\u53ca\u5230\u7684\u4e00\u4e9b\u5185\u5bb9\u3002","title":"Memory access"},{"location":"CPU/Memory-access/Memory\u2013access/#memoryprocessor-transfer","text":"When the processor reads from the memory subsystem into a register or writes a register's value to memory, the amount of data transferred is often a word . Historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments. In simple memory subsystems, the word is transferred over the memory data bus , which typically has a width of a word or half-word. In memory subsystems that use caches , the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used. \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7ed9\u51fa\u4e86Memory\u2013processor transfer\u7684\u4e00\u4e2a\u7b80\u5355\u6a21\u578b\uff0c\u8fd9\u5176\u4e2d\u4f1a\u6d89\u53ca\u4e00\u7cfb\u5217\u95ee\u9898\uff0c\u9700\u8981\u8fdb\u884c\u6df1\u5165\u5206\u6790\uff0c\u672c\u7ae0\u540e\u7eed\u7ae0\u8282\u4f1a\u5bf9\u6b64\u8fdb\u884c\u5c55\u5f00\u3002","title":"Memory\u2013processor transfer"},{"location":"CPU/Memory-access/Memory\u2013access/#register-memory-architecture","text":"","title":"Register memory architecture"},{"location":"CPU/Memory-access/Memory\u2013access/#loadstore-architecture","text":"","title":"Load\u2013store architecture"},{"location":"CPU/Memory-access/Memory-alignment/","text":"\u5173\u4e8e\u672c\u7ae0 \u5728\u4e0a\u4e00\u8282\u4e2d\u7ed9\u51fa\u4e86Memory\u2013processor transfer\u7684\u4e00\u4e2a\u7b80\u5355\u6a21\u578b\uff0c\u672c\u8282\u63d0\u4f9bmemory alignment\u7684\u89d2\u5ea6\u5bf9\u6b64\u8fdb\u884c\u8be6\u7ec6\u4ecb\u7ecd\uff0c\u901a\u8fc7\u8fd9\u4e9b\u5206\u6790\uff0c\u8bfb\u8005\u5e94\u8be5\u80fd\u591f\u5bf9\u6b64\u6709\u66f4\u52a0\u6df1\u523b\u7684\u8ba4\u77e5\u3002","title":"Introduction"},{"location":"CPU/Memory-access/Memory-alignment/#_1","text":"\u5728\u4e0a\u4e00\u8282\u4e2d\u7ed9\u51fa\u4e86Memory\u2013processor transfer\u7684\u4e00\u4e2a\u7b80\u5355\u6a21\u578b\uff0c\u672c\u8282\u63d0\u4f9bmemory alignment\u7684\u89d2\u5ea6\u5bf9\u6b64\u8fdb\u884c\u8be6\u7ec6\u4ecb\u7ecd\uff0c\u901a\u8fc7\u8fd9\u4e9b\u5206\u6790\uff0c\u8bfb\u8005\u5e94\u8be5\u80fd\u591f\u5bf9\u6b64\u6709\u66f4\u52a0\u6df1\u523b\u7684\u8ba4\u77e5\u3002","title":"\u5173\u4e8e\u672c\u7ae0"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/","text":"Data alignment: Straighten up and fly right NOTE: \u672c\u6587\u7ed9\u51fa\u4e86memory access\u8be6\u7ec6\u7ec6\u8282\u4ee5\u53ca\u76f8\u5173\u95ee\u9898\u3002\u5176\u4e2d\u7684 memory access granularity \u6982\u5ff5\u5c24\u5176\u91cd\u8981\uff0c\u7ed3\u5408\u524d\u9762\u7ae0\u8282\u7684\u5185\u5bb9\uff0c\u5728\u6b64\u53ef\u4ee5\u9884\u544a\u8bfb\u8005\u76ee\u524d\u5927\u591a\u6570CPU\u7684 memory access granularity \u53d6 word size \u3002 Memory access granularity Programmers are conditioned to think of memory as a simple array of bytes. Among C and its descendants, char* is ubiquitous(\u666e\u904d\u5b58\u5728\u7684) as meaning \u201ca block of memory\u201d, and even Java\u2122 has its byte[] type to represent raw memory. Figure 1. How programmers see memory However, your computer\u2019s processor does not read from and write to memory in byte-sized chunks. Instead, it accesses memory in two-, four-, eight- 16- or even 32-byte chunks. We\u2019ll call the size in which a processor accesses memory its memory access granularity . NOTE: \u9700\u8981\u7406\u89e3granularity\u7684\u542b\u4e49\uff0c\u5b83\u7684\u4e2d\u6587\u610f\u601d\u662f \u7c92\u5ea6 \uff0c\u53ef\u4ee5\u628a\u5b83\u770b\u505a\u662f \u5355\u4f4d \u7684\u610f\u601d\uff0c\u5b83\u5177\u6709 \u539f\u5b50\u6027 \u3002 memory access granularity \u662fCPU\u4ecememory\u4e2d\u8bfb\u53d6\u6570\u636e\u7684 \u5355\u4f4d \uff0c\u6240\u4ee5CPU\u65e0\u6cd5\u4ecememory\u4e2d\u8bfb\u53d6\u534a\u4e2a\u5355\u4f4d\u7684\u6570\u636e\uff0c\u53ea\u80fd\u591f\u8bfb\u53d6\u4e00\u4e2a\u5355\u4f4d\u7684\u6570\u636e\u3002\u4e0b\u9762\u7684Figure 2\u5c31\u975e\u5e38\u76f4\u89c2\u5730\u5c55\u793a\u4e86CPU\u89c6\u89d2\u7684memory\u3002\u901a\u8fc7\u524d\u9762\u7684\u8fd9\u4e9b\u5206\u6790\uff0c\u6211\u4eec\u5e94\u8be5\u77e5\u9053\u7684\u662f\uff0cCPU\u53ea\u80fd\u591f\u4ece\u4f4d\u7f6e 0 \u3001 4 \u3001 8 \u7b49\u4f4d\u7f6e\u5f00\u59cb\u8bfb\u53d6\u6570\u636e\uff0c\u8fd9\u4e9b\u4f4d\u7f6e\u6211\u4eec\u901a\u5e38\u5c06\u5b83\u4eec\u79f0\u4e3amemory access boundary\uff08\u5728\u540e\u7eed\u7ae0\u8282\u4f1a\u4ecb\u7ecd\uff09\uff0c\u663e\u7136CPU access boundary\u662f memory access granularity \u7684\u6574\u6570\u500d\uff0c\u5982\u679c\u4e00\u4e2a\u6570\u636e\u7684\u5b58\u50a8\u4f4d\u7f6e\u662fmemory access boundary\uff0c\u5219\u79f0\u4e3a align to memory access granularity \uff08\u5bf9\u9f50\uff09\uff0c\u4f7f\u7528aligned\u6765\u5f62\u5bb9\u8fd9\u6837\u7684\u5730\u5740\uff0c\u5426\u5219\u5c31\u662funaligned\u3002\u901a\u8fc7\u540e\u9762\u7684\u7ae0\u8282\uff0c\u6211\u4eec\u4f1a\u770b\u5230\uff0caligned address\u76f8\u6bd4\u4e8eunaligned address\u6709\u7740\u8bf8\u591a\u4f18\u52bf\u3002 Figure 2. How processors see memory If you don\u2019t understand and address alignment issues in your software, the following scenarios, in increasing order of severity, are all possible: Your software will run slower. Your application will lock up. Your operating system will crash. Your software will silently fail, yielding incorrect results. Alignment fundamentals To illustrate the principles behind alignment, examine a constant task, and how it\u2019s affected by a processor\u2019s memory access granularity . The task is simple: first read four bytes from address 0 into the processor\u2019s register. Then read four bytes from address 1 into the same register. First examine what would happen on a processor with a one-byte memory access granularity: Figure 3. Single-byte memory access granularity This fits in with the naive programmer\u2019s model of how memory works: it takes the same four memory accesses to read from address 0 as it does from address 1. Now see what would happen on a processor with two-byte granularity, like the original 68000: Figure 4. Double-byte memory access granularity When reading from address 0, a processor with two-byte granularity takes half the number of memory accesses as a processor with one-byte granularity. Because each memory access entails a fixed amount overhead, minimizing the number of accesses can really help performance. NOTE: \u8fd9\u53e5\u8bdd\u7684\u610f\u601d\u662fa processor with two-byte granularity\u8bfb\u53d64\u4e2a\u5b57\u8282\u82b1\u8d39\u7684\u65f6\u95f4\u6bd4a processor with one-byte granularity\u82b1\u8d39\u7684\u65f6\u95f4\u8981\u5c11\u4e00\u534a\uff1b However, notice what happens when reading from address 1. Because the address doesn\u2019t fall evenly on the processor\u2019s memory access boundary , the processor has extra work to do. Such an address is known as an unaligned address . Because address 1 is unaligned , a processor with two-byte granularity must perform an extra memory access, slowing down the operation Finally, examine what would happen on a processor with four-byte memory access granularity, like the 68030 or PowerPC\u00ae 601: Figure 5. Quad-byte memory access granularity A processor with four-byte granularity can slurp up four bytes from an aligned address with one read. Also note that reading from an unaligned address doubles the access count. Now that you understand the fundamentals behind aligned data access , you can explore some of the issues related to alignment. Lazy processors A processor has to perform some tricks when instructed to access an unaligned address . Going back to the example of reading four bytes from address 1 on a processor with four-byte granularity , you can work out exactly what needs to be done: Figure 6. How processors handle unaligned memory access The processor needs to read the first chunk of the unaligned address and shift out the \u201cunwanted\u201d bytes from the first chunk. Then it needs to read the second chunk of the unaligned address and shift out some of its information. Finally, the two are merged together for placement in the register. It\u2019s a lot of work. Some processors just aren\u2019t willing to do all of that work for you. The original 68000 was a processor with two-byte granularity and lacked the circuitry to cope with unaligned addresses . When presented with such an address, the processor would throw an exception. The original Mac OS didn\u2019t take very kindly to this exception, and would usually demand the user restart the machine. Ouch. Later processors in the 680\u00d70 series, such as the 68020, lifted this restriction and performed the necessary work for you. This explains why some old software that works on the 68020 crashes on the 68000. It also explains why, way back when, some old Mac coders initialized pointers with odd addresses. On the original Mac, if the pointer was accessed without being reassigned to a valid address, the Mac would immediately drop into the debugger. Often they could then examine the calling chain stack and figure out where the mistake was. All processors have a finite number of transistors to get work done. Adding unaligned address access support cuts into this \u201ctransistor budget.\u201d These transistors could otherwise be used to make other portions of the processor work faster, or add new functionality altogether. An example of a processor that sacrifices unaligned address access support in the name of speed is MIPS. MIPS is a great example of a processor that does away with almost all frivolity in the name of getting real work done faster. The PowerPC takes a hybrid approach. Every PowerPC processor to date has hardware support for unaligned 32-bit integer access. While you still pay a performance penalty for unaligned access, it tends to be small. On the other hand, modern PowerPC processors lack hardware support for unaligned 64-bit floating-point access. When asked to load an unaligned floating-point number from memory, modern PowerPC processors will throw an exception and have the operating system perform the alignment chores in software . Performing alignment in software is much slower than performing it in hardware. NOTE : \u6709\u7684processor\u538b\u6839\u5c31\u4e0d\u652f\u6301unaligned address access Speed Writing some tests illustrates the performance penalties of unaligned memory access . The test is simple: you read, negate, and write back the numbers in a ten-megabyte buffer. These tests have two variables: The size, in bytes, in which you process the buffer. First you\u2019ll process the buffer one byte at a time. Then you\u2019ll move onto two-, four- and eight-bytes at a time. The alignment of the buffer. You\u2019ll stagger the alignment of the buffer by incrementing the pointer to the buffer and running each test again. These tests were performed on a 800 MHz PowerBook G4. To help normalize performance fluctuations from interrupt processing, each test was run ten times, keeping the average of the runs. First up is the test that operates on a single byte at a time: Listing 1. Munging data one byte at a time void Munge8( void \u2217data, uint32_t size ) { uint8_t \u2217data8 = (uint8_t\u2217) data; uint8_t \u2217data8End = data8 + size; while( data8 != data8End ) { \u2217data8++ = \u2011\u2217data8; } } It took an average of 67,364 microseconds to execute this function. Now modify it to work on two bytes at a time instead of one byte at a time \u2014 which will halve the number of memory accesses: Listing 2. Munging data two bytes at a time void Munge16( void \u2217data, uint32_t size ) { uint16_t \u2217data16 = (uint16_t\u2217) data; uint16_t \u2217data16End = data16 + (size >> 1); /\u2217 Divide size by 2. \u2217/ uint8_t \u2217data8 = (uint8_t\u2217) data16End; uint8_t \u2217data8End = data8 + (size & 0x00000001); /\u2217 Strip upper 31 bits. \u2217/ while( data16 != data16End ) { \u2217data16++ = \u2011\u2217data16; } while( data8 != data8End ) { \u2217data8++ = \u2011\u2217data8; } } This function took 48,765 microseconds to process the same ten-megabyte buffer \u2014 38% faster than Munge8 . However, that buffer was aligned. If the buffer is unaligned, the time required increases to 66,385 microseconds \u2014 about a 27% speed penalty. The following chart illustrates the performance pattern of aligned memory accesses versus unaligned accesses: Figure 7. Single-byte access versus double-byte access The first thing you notice is that accessing memory one byte at a time is uniformly slow. The second item of interest is that when accessing memory two bytes at a time, whenever the address is not evenly divisible by two, that 27% speed penalty rears its ugly head. Now up the ante, and process the buffer four bytes at a time: Listing 3. Munging data four bytes at a time void Munge32( void \u2217data, uint32_t size ) { uint32_t \u2217data32 = (uint32_t\u2217) data; uint32_t \u2217data32End = data32 + (size >> 2); /\u2217 Divide size by 4. \u2217/ uint8_t \u2217data8 = (uint8_t\u2217) data32End; uint8_t \u2217data8End = data8 + (size & 0x00000003); /\u2217 Strip upper 30 bits. \u2217/ while( data32 != data32End ) { \u2217data32++ = \u2011\u2217data32; } while( data8 != data8End ) { \u2217data8++ = \u2011\u2217data8; } } This function processes an aligned buffer in 43,043 microseconds and an unaligned buffer in 55,775 microseconds, respectively. Thus, on this test machine, accessing unaligned memory four bytes at a time is slower than accessing aligned memory two bytes at a time: Figure 8. Single- versus double- versus quad-byte access Now for the horror story: processing the buffer eight bytes at a time. Listing 4. Munging data eight bytes at a time void Munge64( void \u2217data, uint32_t size ) { double \u2217data64 = (double\u2217) data; double \u2217data64End = data64 + (size >> 3); /\u2217 Divide size by 8. \u2217/ uint8_t \u2217data8 = (uint8_t\u2217) data64End; uint8_t \u2217data8End = data8 + (size & 0x00000007); /\u2217 Strip upper 29 bits. \u2217/ while( data64 != data64End ) { \u2217data64++ = \u2011\u2217data64; } while( data8 != data8End ) { \u2217data8++ = \u2011\u2217data8; } } Munge64 processes an aligned buffer in 39,085 microseconds \u2014 about 10% faster than processing the buffer four bytes at a time. However, processing an unaligned buffer takes an amazing 1,841,155 microseconds \u2014 two orders of magnitude slower than aligned access, an outstanding 4,610% performance penalty! What happened? Because modern PowerPC processors lack hardware support for unaligned floating-point access, the processor throws an exception for each unaligned access. The operating system catches this exception and performs the alignment in software. Here\u2019s a chart illustrating the penalty, and when it occurs: Figure 9. Multiple-byte access comparison The penalties for one-, two- and four-byte unaligned access are dwarfed by the horrendous unaligned eight-byte penalty. Maybe this chart, removing the top (and thus the tremendous gulf between the two numbers), will be clearer: Figure 10. Multiple-byte access comparison #2 There\u2019s another subtle insight hidden in this data. Compare eight-byte access speeds on four-byte boundaries: Figure 11. Multiple-byte access comparison #3 Notice accessing memory eight bytes at a time on four- and twelve- byte boundaries is slower than reading the same memory four or even two bytes at a time. While PowerPCs have hardware support for four-byte aligned eight-byte doubles, you still pay a performance penalty if you use that support. Granted, it\u2019s no where near the 4,610% penalty, but it\u2019s certainly noticeable. Moral of the story: accessing memory in large chunks can be slower than accessing memory in small chunks, if that access is not aligned. Atomicity All modern processors offer atomic instructions . These special instructions are crucial for synchronizing two or more concurrent tasks. As the name implies, atomic instructions must be indivisible \u2014 that\u2019s why they\u2019re so handy for synchronization: they can\u2019t be preempted. It turns out that in order for atomic instructions to perform correctly, the addresses you pass them must be at least four-byte aligned. This is because of a subtle interaction between atomic instructions and virtual memory . If an address is unaligned, it requires at least two memory accesses. But what happens if the desired data spans two pages of virtual memory ? This could lead to a situation where the first page is resident while the last page is not. Upon access, in the middle of the instruction, a page fault would be generated, executing the virtual memory management swap-in code, destroying the atomicity of the instruction . To keep things simple and correct, both the 68K and PowerPC require that atomically manipulated addresses always be at least four-byte aligned. Unfortunately, the PowerPC does not throw an exception when atomically storing to an unaligned address. Instead, the store simply always fails. This is bad because most atomic functions are written to retry upon a failed store, under the assumption they were preempted. These two circumstances combine to where your program will go into an infinite loop if you attempt to atomically store to an unaligned address. Oops. Altivec Altivec is all about speed. Unaligned memory access slows down the processor and costs precious transistors. Thus, the Altivec engineers took a page from the MIPS playbook and simply don\u2019t support unaligned memory access. Because Altivec works with sixteen-byte chunks at a time, all addresses passed to Altivec must be sixteen-byte aligned. What\u2019s scary is what happens if your address is not aligned. Altivec won\u2019t throw an exception to warn you about the unaligned address. Instead, Altivec simply ignores the lower four bits of the address and charges ahead, operating on the wrong address . This means your program may silently corrupt memory or return incorrect results if you don\u2019t explicitly make sure all your data is aligned. There is an advantage to Altivec\u2019s bit-stripping ways. Because you don\u2019t need to explicitly truncate (align-down) an address, this behavior can save you an instruction or two when handing addresses to the processor. This is not to say Altivec can\u2019t process unaligned memory. You can find detailed instructions how to do so on the Altivec Programming Environments Manual (see resources on the right). It requires more work, but because memory is so slow compared to the processor, the overhead for such shenanigans is surprisingly low. Structure alignment Examine the following structure: Listing 5. An innocent structure void Munge64( void \u2217data, uint32_t size ) { typedef struct { char a; long b; char c; } Struct; What is the size of this structure in bytes? Many programmers will answer \u201c6 bytes.\u201d It makes sense: one byte for a , four bytes for b and another byte for c . 1 + 4 + 1 equals 6. Here\u2019s how it would lay out in memory: Table 1. Structure size in bytes Field Type Field Name Field Offset Field Size Field End char a 0 1 1 long b 1 4 5 char c 5 1 6 Total size in bytes: 6 However, if you were to ask your compiler to sizeof( Struct ) , chances are the answer you\u2019d get back would be greater than six, perhaps eight or even twenty-four. There\u2019s two reasons for this: backwards compatibility and efficiency. First, backwards compatibility. Remember the 68000 was a processor with two-byte memory access granularity, and would throw an exception upon encountering an odd address. If you were to read from or write to field b , you\u2019d attempt to access an odd address. If a debugger weren\u2019t installed, the old Mac OS would throw up a System Error dialog box with one button: Restart. Yikes! So, instead of laying out your fields just the way you wrote them, the compiler padded the structure so that b and c would reside at even addresses: Table 2. Structure with compiler padding Field Type Field Name Field Offset Field Size Field End char a 0 1 1 padding 1 1 2 long b 2 4 6 char c 6 1 7 padding 7 1 8 Total Size in Bytes: 8 Padding is the act of adding otherwise unused space to a structure to make fields line up in a desired way. Now, when the 68020 came out with built-in hardware support for unaligned memory access, this padding was unnecessary. However, it didn\u2019t hurt anything, and it even helped a little in performance. The second reason is efficiency. Nowadays, on PowerPC machines, two-byte alignment is nice, but four-byte or eight-byte is better. You probably don\u2019t care anymore that the original 68000 choked on unaligned structures, but you probably care about potential 4,610% performance penalties, which can happen if a double field doesn\u2019t sit aligned in a structure of your devising. Conclusion If you don\u2019t understand and explicitly code for data alignment: Your software may hit performance-killing unaligned memory access exceptions, which invoke very expensive alignment exception handlers. Your application may attempt to atomically store to an unaligned address, causing your application to lock up. Your application may attempt to pass an unaligned address to Altivec, resulting in Altivec reading from and/or writing to the wrong part of memory, silently corrupting data or yielding incorrect results. Credits Thanks to Alex Rosenberg and Ian Ollmann for feedback, Matt Slot for his FastTimes timing library, and Duane Hayes for providing a bevy of testing machines.","title":"Data-alignment-Straighten-up-and-fly-right"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/#data-alignment-straighten-up-and-fly-right","text":"NOTE: \u672c\u6587\u7ed9\u51fa\u4e86memory access\u8be6\u7ec6\u7ec6\u8282\u4ee5\u53ca\u76f8\u5173\u95ee\u9898\u3002\u5176\u4e2d\u7684 memory access granularity \u6982\u5ff5\u5c24\u5176\u91cd\u8981\uff0c\u7ed3\u5408\u524d\u9762\u7ae0\u8282\u7684\u5185\u5bb9\uff0c\u5728\u6b64\u53ef\u4ee5\u9884\u544a\u8bfb\u8005\u76ee\u524d\u5927\u591a\u6570CPU\u7684 memory access granularity \u53d6 word size \u3002","title":"Data alignment: Straighten up and fly right"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/#memory-access-granularity","text":"Programmers are conditioned to think of memory as a simple array of bytes. Among C and its descendants, char* is ubiquitous(\u666e\u904d\u5b58\u5728\u7684) as meaning \u201ca block of memory\u201d, and even Java\u2122 has its byte[] type to represent raw memory. Figure 1. How programmers see memory However, your computer\u2019s processor does not read from and write to memory in byte-sized chunks. Instead, it accesses memory in two-, four-, eight- 16- or even 32-byte chunks. We\u2019ll call the size in which a processor accesses memory its memory access granularity . NOTE: \u9700\u8981\u7406\u89e3granularity\u7684\u542b\u4e49\uff0c\u5b83\u7684\u4e2d\u6587\u610f\u601d\u662f \u7c92\u5ea6 \uff0c\u53ef\u4ee5\u628a\u5b83\u770b\u505a\u662f \u5355\u4f4d \u7684\u610f\u601d\uff0c\u5b83\u5177\u6709 \u539f\u5b50\u6027 \u3002 memory access granularity \u662fCPU\u4ecememory\u4e2d\u8bfb\u53d6\u6570\u636e\u7684 \u5355\u4f4d \uff0c\u6240\u4ee5CPU\u65e0\u6cd5\u4ecememory\u4e2d\u8bfb\u53d6\u534a\u4e2a\u5355\u4f4d\u7684\u6570\u636e\uff0c\u53ea\u80fd\u591f\u8bfb\u53d6\u4e00\u4e2a\u5355\u4f4d\u7684\u6570\u636e\u3002\u4e0b\u9762\u7684Figure 2\u5c31\u975e\u5e38\u76f4\u89c2\u5730\u5c55\u793a\u4e86CPU\u89c6\u89d2\u7684memory\u3002\u901a\u8fc7\u524d\u9762\u7684\u8fd9\u4e9b\u5206\u6790\uff0c\u6211\u4eec\u5e94\u8be5\u77e5\u9053\u7684\u662f\uff0cCPU\u53ea\u80fd\u591f\u4ece\u4f4d\u7f6e 0 \u3001 4 \u3001 8 \u7b49\u4f4d\u7f6e\u5f00\u59cb\u8bfb\u53d6\u6570\u636e\uff0c\u8fd9\u4e9b\u4f4d\u7f6e\u6211\u4eec\u901a\u5e38\u5c06\u5b83\u4eec\u79f0\u4e3amemory access boundary\uff08\u5728\u540e\u7eed\u7ae0\u8282\u4f1a\u4ecb\u7ecd\uff09\uff0c\u663e\u7136CPU access boundary\u662f memory access granularity \u7684\u6574\u6570\u500d\uff0c\u5982\u679c\u4e00\u4e2a\u6570\u636e\u7684\u5b58\u50a8\u4f4d\u7f6e\u662fmemory access boundary\uff0c\u5219\u79f0\u4e3a align to memory access granularity \uff08\u5bf9\u9f50\uff09\uff0c\u4f7f\u7528aligned\u6765\u5f62\u5bb9\u8fd9\u6837\u7684\u5730\u5740\uff0c\u5426\u5219\u5c31\u662funaligned\u3002\u901a\u8fc7\u540e\u9762\u7684\u7ae0\u8282\uff0c\u6211\u4eec\u4f1a\u770b\u5230\uff0caligned address\u76f8\u6bd4\u4e8eunaligned address\u6709\u7740\u8bf8\u591a\u4f18\u52bf\u3002 Figure 2. How processors see memory If you don\u2019t understand and address alignment issues in your software, the following scenarios, in increasing order of severity, are all possible: Your software will run slower. Your application will lock up. Your operating system will crash. Your software will silently fail, yielding incorrect results.","title":"Memory access granularity"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/#alignment-fundamentals","text":"To illustrate the principles behind alignment, examine a constant task, and how it\u2019s affected by a processor\u2019s memory access granularity . The task is simple: first read four bytes from address 0 into the processor\u2019s register. Then read four bytes from address 1 into the same register. First examine what would happen on a processor with a one-byte memory access granularity: Figure 3. Single-byte memory access granularity This fits in with the naive programmer\u2019s model of how memory works: it takes the same four memory accesses to read from address 0 as it does from address 1. Now see what would happen on a processor with two-byte granularity, like the original 68000: Figure 4. Double-byte memory access granularity When reading from address 0, a processor with two-byte granularity takes half the number of memory accesses as a processor with one-byte granularity. Because each memory access entails a fixed amount overhead, minimizing the number of accesses can really help performance. NOTE: \u8fd9\u53e5\u8bdd\u7684\u610f\u601d\u662fa processor with two-byte granularity\u8bfb\u53d64\u4e2a\u5b57\u8282\u82b1\u8d39\u7684\u65f6\u95f4\u6bd4a processor with one-byte granularity\u82b1\u8d39\u7684\u65f6\u95f4\u8981\u5c11\u4e00\u534a\uff1b However, notice what happens when reading from address 1. Because the address doesn\u2019t fall evenly on the processor\u2019s memory access boundary , the processor has extra work to do. Such an address is known as an unaligned address . Because address 1 is unaligned , a processor with two-byte granularity must perform an extra memory access, slowing down the operation Finally, examine what would happen on a processor with four-byte memory access granularity, like the 68030 or PowerPC\u00ae 601: Figure 5. Quad-byte memory access granularity A processor with four-byte granularity can slurp up four bytes from an aligned address with one read. Also note that reading from an unaligned address doubles the access count. Now that you understand the fundamentals behind aligned data access , you can explore some of the issues related to alignment.","title":"Alignment fundamentals"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/#lazy-processors","text":"A processor has to perform some tricks when instructed to access an unaligned address . Going back to the example of reading four bytes from address 1 on a processor with four-byte granularity , you can work out exactly what needs to be done: Figure 6. How processors handle unaligned memory access The processor needs to read the first chunk of the unaligned address and shift out the \u201cunwanted\u201d bytes from the first chunk. Then it needs to read the second chunk of the unaligned address and shift out some of its information. Finally, the two are merged together for placement in the register. It\u2019s a lot of work. Some processors just aren\u2019t willing to do all of that work for you. The original 68000 was a processor with two-byte granularity and lacked the circuitry to cope with unaligned addresses . When presented with such an address, the processor would throw an exception. The original Mac OS didn\u2019t take very kindly to this exception, and would usually demand the user restart the machine. Ouch. Later processors in the 680\u00d70 series, such as the 68020, lifted this restriction and performed the necessary work for you. This explains why some old software that works on the 68020 crashes on the 68000. It also explains why, way back when, some old Mac coders initialized pointers with odd addresses. On the original Mac, if the pointer was accessed without being reassigned to a valid address, the Mac would immediately drop into the debugger. Often they could then examine the calling chain stack and figure out where the mistake was. All processors have a finite number of transistors to get work done. Adding unaligned address access support cuts into this \u201ctransistor budget.\u201d These transistors could otherwise be used to make other portions of the processor work faster, or add new functionality altogether. An example of a processor that sacrifices unaligned address access support in the name of speed is MIPS. MIPS is a great example of a processor that does away with almost all frivolity in the name of getting real work done faster. The PowerPC takes a hybrid approach. Every PowerPC processor to date has hardware support for unaligned 32-bit integer access. While you still pay a performance penalty for unaligned access, it tends to be small. On the other hand, modern PowerPC processors lack hardware support for unaligned 64-bit floating-point access. When asked to load an unaligned floating-point number from memory, modern PowerPC processors will throw an exception and have the operating system perform the alignment chores in software . Performing alignment in software is much slower than performing it in hardware. NOTE : \u6709\u7684processor\u538b\u6839\u5c31\u4e0d\u652f\u6301unaligned address access","title":"Lazy processors"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/#speed","text":"Writing some tests illustrates the performance penalties of unaligned memory access . The test is simple: you read, negate, and write back the numbers in a ten-megabyte buffer. These tests have two variables: The size, in bytes, in which you process the buffer. First you\u2019ll process the buffer one byte at a time. Then you\u2019ll move onto two-, four- and eight-bytes at a time. The alignment of the buffer. You\u2019ll stagger the alignment of the buffer by incrementing the pointer to the buffer and running each test again. These tests were performed on a 800 MHz PowerBook G4. To help normalize performance fluctuations from interrupt processing, each test was run ten times, keeping the average of the runs. First up is the test that operates on a single byte at a time: Listing 1. Munging data one byte at a time void Munge8( void \u2217data, uint32_t size ) { uint8_t \u2217data8 = (uint8_t\u2217) data; uint8_t \u2217data8End = data8 + size; while( data8 != data8End ) { \u2217data8++ = \u2011\u2217data8; } } It took an average of 67,364 microseconds to execute this function. Now modify it to work on two bytes at a time instead of one byte at a time \u2014 which will halve the number of memory accesses: Listing 2. Munging data two bytes at a time void Munge16( void \u2217data, uint32_t size ) { uint16_t \u2217data16 = (uint16_t\u2217) data; uint16_t \u2217data16End = data16 + (size >> 1); /\u2217 Divide size by 2. \u2217/ uint8_t \u2217data8 = (uint8_t\u2217) data16End; uint8_t \u2217data8End = data8 + (size & 0x00000001); /\u2217 Strip upper 31 bits. \u2217/ while( data16 != data16End ) { \u2217data16++ = \u2011\u2217data16; } while( data8 != data8End ) { \u2217data8++ = \u2011\u2217data8; } } This function took 48,765 microseconds to process the same ten-megabyte buffer \u2014 38% faster than Munge8 . However, that buffer was aligned. If the buffer is unaligned, the time required increases to 66,385 microseconds \u2014 about a 27% speed penalty. The following chart illustrates the performance pattern of aligned memory accesses versus unaligned accesses: Figure 7. Single-byte access versus double-byte access The first thing you notice is that accessing memory one byte at a time is uniformly slow. The second item of interest is that when accessing memory two bytes at a time, whenever the address is not evenly divisible by two, that 27% speed penalty rears its ugly head. Now up the ante, and process the buffer four bytes at a time: Listing 3. Munging data four bytes at a time void Munge32( void \u2217data, uint32_t size ) { uint32_t \u2217data32 = (uint32_t\u2217) data; uint32_t \u2217data32End = data32 + (size >> 2); /\u2217 Divide size by 4. \u2217/ uint8_t \u2217data8 = (uint8_t\u2217) data32End; uint8_t \u2217data8End = data8 + (size & 0x00000003); /\u2217 Strip upper 30 bits. \u2217/ while( data32 != data32End ) { \u2217data32++ = \u2011\u2217data32; } while( data8 != data8End ) { \u2217data8++ = \u2011\u2217data8; } } This function processes an aligned buffer in 43,043 microseconds and an unaligned buffer in 55,775 microseconds, respectively. Thus, on this test machine, accessing unaligned memory four bytes at a time is slower than accessing aligned memory two bytes at a time: Figure 8. Single- versus double- versus quad-byte access Now for the horror story: processing the buffer eight bytes at a time. Listing 4. Munging data eight bytes at a time void Munge64( void \u2217data, uint32_t size ) { double \u2217data64 = (double\u2217) data; double \u2217data64End = data64 + (size >> 3); /\u2217 Divide size by 8. \u2217/ uint8_t \u2217data8 = (uint8_t\u2217) data64End; uint8_t \u2217data8End = data8 + (size & 0x00000007); /\u2217 Strip upper 29 bits. \u2217/ while( data64 != data64End ) { \u2217data64++ = \u2011\u2217data64; } while( data8 != data8End ) { \u2217data8++ = \u2011\u2217data8; } } Munge64 processes an aligned buffer in 39,085 microseconds \u2014 about 10% faster than processing the buffer four bytes at a time. However, processing an unaligned buffer takes an amazing 1,841,155 microseconds \u2014 two orders of magnitude slower than aligned access, an outstanding 4,610% performance penalty! What happened? Because modern PowerPC processors lack hardware support for unaligned floating-point access, the processor throws an exception for each unaligned access. The operating system catches this exception and performs the alignment in software. Here\u2019s a chart illustrating the penalty, and when it occurs: Figure 9. Multiple-byte access comparison The penalties for one-, two- and four-byte unaligned access are dwarfed by the horrendous unaligned eight-byte penalty. Maybe this chart, removing the top (and thus the tremendous gulf between the two numbers), will be clearer: Figure 10. Multiple-byte access comparison #2 There\u2019s another subtle insight hidden in this data. Compare eight-byte access speeds on four-byte boundaries: Figure 11. Multiple-byte access comparison #3 Notice accessing memory eight bytes at a time on four- and twelve- byte boundaries is slower than reading the same memory four or even two bytes at a time. While PowerPCs have hardware support for four-byte aligned eight-byte doubles, you still pay a performance penalty if you use that support. Granted, it\u2019s no where near the 4,610% penalty, but it\u2019s certainly noticeable. Moral of the story: accessing memory in large chunks can be slower than accessing memory in small chunks, if that access is not aligned.","title":"Speed"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/#atomicity","text":"All modern processors offer atomic instructions . These special instructions are crucial for synchronizing two or more concurrent tasks. As the name implies, atomic instructions must be indivisible \u2014 that\u2019s why they\u2019re so handy for synchronization: they can\u2019t be preempted. It turns out that in order for atomic instructions to perform correctly, the addresses you pass them must be at least four-byte aligned. This is because of a subtle interaction between atomic instructions and virtual memory . If an address is unaligned, it requires at least two memory accesses. But what happens if the desired data spans two pages of virtual memory ? This could lead to a situation where the first page is resident while the last page is not. Upon access, in the middle of the instruction, a page fault would be generated, executing the virtual memory management swap-in code, destroying the atomicity of the instruction . To keep things simple and correct, both the 68K and PowerPC require that atomically manipulated addresses always be at least four-byte aligned. Unfortunately, the PowerPC does not throw an exception when atomically storing to an unaligned address. Instead, the store simply always fails. This is bad because most atomic functions are written to retry upon a failed store, under the assumption they were preempted. These two circumstances combine to where your program will go into an infinite loop if you attempt to atomically store to an unaligned address. Oops.","title":"Atomicity"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/#altivec","text":"Altivec is all about speed. Unaligned memory access slows down the processor and costs precious transistors. Thus, the Altivec engineers took a page from the MIPS playbook and simply don\u2019t support unaligned memory access. Because Altivec works with sixteen-byte chunks at a time, all addresses passed to Altivec must be sixteen-byte aligned. What\u2019s scary is what happens if your address is not aligned. Altivec won\u2019t throw an exception to warn you about the unaligned address. Instead, Altivec simply ignores the lower four bits of the address and charges ahead, operating on the wrong address . This means your program may silently corrupt memory or return incorrect results if you don\u2019t explicitly make sure all your data is aligned. There is an advantage to Altivec\u2019s bit-stripping ways. Because you don\u2019t need to explicitly truncate (align-down) an address, this behavior can save you an instruction or two when handing addresses to the processor. This is not to say Altivec can\u2019t process unaligned memory. You can find detailed instructions how to do so on the Altivec Programming Environments Manual (see resources on the right). It requires more work, but because memory is so slow compared to the processor, the overhead for such shenanigans is surprisingly low.","title":"Altivec"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/#structure-alignment","text":"Examine the following structure: Listing 5. An innocent structure void Munge64( void \u2217data, uint32_t size ) { typedef struct { char a; long b; char c; } Struct; What is the size of this structure in bytes? Many programmers will answer \u201c6 bytes.\u201d It makes sense: one byte for a , four bytes for b and another byte for c . 1 + 4 + 1 equals 6. Here\u2019s how it would lay out in memory: Table 1. Structure size in bytes Field Type Field Name Field Offset Field Size Field End char a 0 1 1 long b 1 4 5 char c 5 1 6 Total size in bytes: 6 However, if you were to ask your compiler to sizeof( Struct ) , chances are the answer you\u2019d get back would be greater than six, perhaps eight or even twenty-four. There\u2019s two reasons for this: backwards compatibility and efficiency. First, backwards compatibility. Remember the 68000 was a processor with two-byte memory access granularity, and would throw an exception upon encountering an odd address. If you were to read from or write to field b , you\u2019d attempt to access an odd address. If a debugger weren\u2019t installed, the old Mac OS would throw up a System Error dialog box with one button: Restart. Yikes! So, instead of laying out your fields just the way you wrote them, the compiler padded the structure so that b and c would reside at even addresses: Table 2. Structure with compiler padding Field Type Field Name Field Offset Field Size Field End char a 0 1 1 padding 1 1 2 long b 2 4 6 char c 6 1 7 padding 7 1 8 Total Size in Bytes: 8 Padding is the act of adding otherwise unused space to a structure to make fields line up in a desired way. Now, when the 68020 came out with built-in hardware support for unaligned memory access, this padding was unnecessary. However, it didn\u2019t hurt anything, and it even helped a little in performance. The second reason is efficiency. Nowadays, on PowerPC machines, two-byte alignment is nice, but four-byte or eight-byte is better. You probably don\u2019t care anymore that the original 68000 choked on unaligned structures, but you probably care about potential 4,610% performance penalties, which can happen if a double field doesn\u2019t sit aligned in a structure of your devising.","title":"Structure alignment"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/#conclusion","text":"If you don\u2019t understand and explicitly code for data alignment: Your software may hit performance-killing unaligned memory access exceptions, which invoke very expensive alignment exception handlers. Your application may attempt to atomically store to an unaligned address, causing your application to lock up. Your application may attempt to pass an unaligned address to Altivec, resulting in Altivec reading from and/or writing to the wrong part of memory, silently corrupting data or yielding incorrect results.","title":"Conclusion"},{"location":"CPU/Memory-access/Memory-alignment/Data-alignment-Straighten-up-and-fly-right/#credits","text":"Thanks to Alex Rosenberg and Ian Ollmann for feedback, Matt Slot for his FastTimes timing library, and Duane Hayes for providing a bevy of testing machines.","title":"Credits"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/","text":"Memory Alignment When a computer reads from or writes to a memory address, it will do this in word sized chunks (for example, 4 byte (32-bit) chunks on the MPC8360). Data alignment means putting the data at a memory offset equal to some multiple of the word size , which increases the system's performance due to the way the CPU handles memory. Most CPUs can access only memory aligned addresses . Table 1 show an example of some memory addresses and their alignment on different architectures. Memory Alignment in the MPC8360 The MPC8360 read/write operations are in 4 byte (32-bit) chunks. Thus, only memory addresses that are some multiple of four are considered aligned. The MPC8360 can access only aligned addresses. Reading a word (32 bit) from an aligned address in the MPC8360 (for example 0x0000_0008) can be achieved in a single load instruction. However, reading a word (32 bit) from an unaligned address (for example 0x0000_0009) will take at least two read instructions. Formal Definitions A memory address a , is said to be n-byte aligned when n is a power of two and a is a multiple of n bytes. In this context a byte is the smallest unit of memory access, i.e. each memory address specifies a different byte. An n-byte aligned address would have $log2 n$ least-significant zeros when expressed in binary. A memory access is said to be aligned when the data being accessed is n bytes long and the address is n-byte aligned. When a memory access is not aligned, it is said to be misaligned or Non Aligned. Note that by definition byte memory accesses are always aligned. Purpose of memory alignment The memory subsystem on a modern processor is restricted to accessing memory at the granularity and alignment of its word size; this is the case for a number of reasons. Speed Modern processors have multiple levels of cache memory that data must be pulled through; supporting single-byte reads would make the memory subsystem throughput tightly bound to the execution unit throughput (aka cpu-bound); this is all reminiscent of how PIO mode was surpassed by DMA for many of the same reasons in hard drives. The CPU always reads at its word size (4 bytes on a 32-bit processor), so when you do an unaligned address access \u2014 on a processor that supports it \u2014 the processor is going to read multiple words. The CPU will read each word of memory that your requested address straddles. This causes an amplification of up to 2X the number of memory transactions required to access the requested data. Because of this, it can very easily be slower to read two bytes than four. For example, say you have a struct in memory that looks like this: struct mystruct { char c; // one byte int i; // four bytes short s; // two bytes } On a 32-bit processor it would most likely be aligned like shown here: The processor can read each of these members in one transaction. Say you had a packed version of the struct, maybe from the network where it was packed for transmission efficiency; it might look something like this: Reading the first byte is going to be the same. When you ask the processor to give you 16 bits from 0x0005 it will have to read a word from from 0x0004 and shift left 1 byte to place it in a 16-bit register; some extra work, but most can handle that in one cycle. When you ask for 32 bits from 0x0001 you'll get a 2X amplification. The processor will read from 0x0000 into the result register and shift left 1 byte, then read again from 0x0004 into a temporary register, shift right 3 bytes, then OR it with the result register. Range For any given address space, if the architecture can assume that the 2 LSBs are always 0 (e.g., 32-bit machines) then it can access 4 times more memory (the 2 saved bits can represent 4 distinct states), or the same amount of memory with 2 bits for something like flags. Taking the 2 LSBs off of an address would give you a 4-byte alignment; also referred to as a stride of 4 bytes. Each time an address is incremented it is effectively incrementing bit 2, not bit 0, i.e., the last 2 bits will always continue to be 00 . This can even affect the physical design of the system. If the address bus needs 2 fewer bits, there can be 2 fewer pins on the CPU, and 2 fewer traces on the circuit board. Atomicity The CPU can operate on an aligned word of memory atomically, meaning that no other instruction can interrupt that operation. This is critical to the correct operation of many lock-free data structures and other concurrency paradigms. Conclusion The memory system of a processor is quite a bit more complex and involved than described here; a discussion on how an x86 processor actually addresses memory can help (many processors work similarly). There are many more benefits to adhering to memory alignment that you can read at this IBM article . A computer's primary use is to transform data. Modern memory architectures and technologies have been optimized over decades to facilitate getting more data, in, out, and between more and faster execution units\u2013in a highly reliable way. Bonus: Caches Another alignment-for-performance that I alluded to previously is alignment on cache lines which are (for example, on some CPUs) 64B. For more info on how much performance can be gained by leveraging caches, take a look at Gallery of Processor Cache Effects ; from this question on cache-line sizes Understanding of cache lines can be important for certain types of program optimizations. For example, alignment of data may determine whether an operation touches one or two cache lines. As we saw in the example above, this can easily mean that in the misaligned case, the operation will be twice slower. See also Why does CPU access memory on a word boundary? What does it mean by word size in computer?","title":"Memory-alignment"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/#memory-alignment","text":"When a computer reads from or writes to a memory address, it will do this in word sized chunks (for example, 4 byte (32-bit) chunks on the MPC8360). Data alignment means putting the data at a memory offset equal to some multiple of the word size , which increases the system's performance due to the way the CPU handles memory. Most CPUs can access only memory aligned addresses . Table 1 show an example of some memory addresses and their alignment on different architectures.","title":"Memory Alignment"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/#memory-alignment-in-the-mpc8360","text":"The MPC8360 read/write operations are in 4 byte (32-bit) chunks. Thus, only memory addresses that are some multiple of four are considered aligned. The MPC8360 can access only aligned addresses. Reading a word (32 bit) from an aligned address in the MPC8360 (for example 0x0000_0008) can be achieved in a single load instruction. However, reading a word (32 bit) from an unaligned address (for example 0x0000_0009) will take at least two read instructions.","title":"Memory Alignment in the MPC8360"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/#formal-definitions","text":"A memory address a , is said to be n-byte aligned when n is a power of two and a is a multiple of n bytes. In this context a byte is the smallest unit of memory access, i.e. each memory address specifies a different byte. An n-byte aligned address would have $log2 n$ least-significant zeros when expressed in binary. A memory access is said to be aligned when the data being accessed is n bytes long and the address is n-byte aligned. When a memory access is not aligned, it is said to be misaligned or Non Aligned. Note that by definition byte memory accesses are always aligned.","title":"Formal Definitions"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/#purpose-of-memory-alignment","text":"The memory subsystem on a modern processor is restricted to accessing memory at the granularity and alignment of its word size; this is the case for a number of reasons.","title":"Purpose of memory alignment"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/#speed","text":"Modern processors have multiple levels of cache memory that data must be pulled through; supporting single-byte reads would make the memory subsystem throughput tightly bound to the execution unit throughput (aka cpu-bound); this is all reminiscent of how PIO mode was surpassed by DMA for many of the same reasons in hard drives. The CPU always reads at its word size (4 bytes on a 32-bit processor), so when you do an unaligned address access \u2014 on a processor that supports it \u2014 the processor is going to read multiple words. The CPU will read each word of memory that your requested address straddles. This causes an amplification of up to 2X the number of memory transactions required to access the requested data. Because of this, it can very easily be slower to read two bytes than four. For example, say you have a struct in memory that looks like this: struct mystruct { char c; // one byte int i; // four bytes short s; // two bytes } On a 32-bit processor it would most likely be aligned like shown here: The processor can read each of these members in one transaction. Say you had a packed version of the struct, maybe from the network where it was packed for transmission efficiency; it might look something like this: Reading the first byte is going to be the same. When you ask the processor to give you 16 bits from 0x0005 it will have to read a word from from 0x0004 and shift left 1 byte to place it in a 16-bit register; some extra work, but most can handle that in one cycle. When you ask for 32 bits from 0x0001 you'll get a 2X amplification. The processor will read from 0x0000 into the result register and shift left 1 byte, then read again from 0x0004 into a temporary register, shift right 3 bytes, then OR it with the result register.","title":"Speed"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/#range","text":"For any given address space, if the architecture can assume that the 2 LSBs are always 0 (e.g., 32-bit machines) then it can access 4 times more memory (the 2 saved bits can represent 4 distinct states), or the same amount of memory with 2 bits for something like flags. Taking the 2 LSBs off of an address would give you a 4-byte alignment; also referred to as a stride of 4 bytes. Each time an address is incremented it is effectively incrementing bit 2, not bit 0, i.e., the last 2 bits will always continue to be 00 . This can even affect the physical design of the system. If the address bus needs 2 fewer bits, there can be 2 fewer pins on the CPU, and 2 fewer traces on the circuit board.","title":"Range"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/#atomicity","text":"The CPU can operate on an aligned word of memory atomically, meaning that no other instruction can interrupt that operation. This is critical to the correct operation of many lock-free data structures and other concurrency paradigms.","title":"Atomicity"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/#conclusion","text":"The memory system of a processor is quite a bit more complex and involved than described here; a discussion on how an x86 processor actually addresses memory can help (many processors work similarly). There are many more benefits to adhering to memory alignment that you can read at this IBM article . A computer's primary use is to transform data. Modern memory architectures and technologies have been optimized over decades to facilitate getting more data, in, out, and between more and faster execution units\u2013in a highly reliable way.","title":"Conclusion"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/#bonus-caches","text":"Another alignment-for-performance that I alluded to previously is alignment on cache lines which are (for example, on some CPUs) 64B. For more info on how much performance can be gained by leveraging caches, take a look at Gallery of Processor Cache Effects ; from this question on cache-line sizes Understanding of cache lines can be important for certain types of program optimizations. For example, alignment of data may determine whether an operation touches one or two cache lines. As we saw in the example above, this can easily mean that in the misaligned case, the operation will be twice slower.","title":"Bonus: Caches"},{"location":"CPU/Memory-access/Memory-alignment/Memory-alignment/#see-also","text":"Why does CPU access memory on a word boundary? What does it mean by word size in computer?","title":"See also"},{"location":"CPU/Word/Word(computer-architecture)/","text":"Word (computer architecture) In computing , a word is the natural unit of data used by a particular processor design. A word is a fixed-sized piece of data handled as a unit by the instruction set or the hardware of the processor. The number of bits in a word (the word size , word width , or word length ) is an important characteristic of any specific processor design or computer architecture . NOTE: \u6309\u7167Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e\u76841.2.4 \u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807 \u4e2d\u7ed9\u51fa\u7684\u5b9a\u4e49\u6bd4\u8f83\u5bb9\u6613\u7406\u89e3\uff1a \u6307\u5904\u7406\u673a \u8fd0\u7b97\u5668 \uff08ALU\uff09\u4e2d\u4e00\u6b21\u80fd\u591f\u5b8c\u6210\u4e8c\u8fdb\u5236\u6570\u8fd0\u7b97\u7684 \u4f4d\u6570 The size of a word is reflected in many aspects of a computer's structure and operation; the majority of the registers in a processor are usually word sized and the largest piece of data that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. The largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used). Uses of words Depending on how a computer is organized, word-size units may be used for: Fixed point numbers Holders for fixed point , usually integer , numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word \uff08programmer\u53ef\u4ee5\u636e\u6b64\u6765\u786e\u5b9aword size\uff09. The other sizes, if any, are likely to be multiples or fractions of the word size. The smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder. Floating point numbers Holders for floating point numerical values are typically either a word or a multiple of a word. Addresses Holders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size. NOTE: \u5373\u6307\u9488\u7c7b\u578b\u7684\u957f\u5ea6 Registers Processor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. Many computer architectures use general-purpose registers that are capable of storing data in multiple representations. These registers must be sized to hold the largest of the available types. Historically, this determined the word size of the architecture. Memory\u2013processor transfer When the processor reads from the memory subsystem into a register or writes a register's value to memory, the amount of data transferred is often a word . Historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments. In simple memory subsystems, the word is transferred over the memory data bus , which typically has a width of a word or half-word. In memory subsystems that use caches , the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used. NOTE: \u8fd9\u4e2a\u975e\u5e38\u91cd\u8981\uff0c\u540e\u9762\u7684\u7ae0\u8282\u4f1a\u5bf9\u6b64\u8fdb\u884c\u8be6\u7ec6\u8ba8\u8bba Unit of address resolution In a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. In most computers, the unit is either a character (e.g. a byte) or a word. (A few computers have used bit resolution.) If the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. On the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation). NOTE: \u8fd9\u4e2a\u548c\u524d\u9762\u7684 Memory\u2013processor transfer \u662f\u7d27\u5bc6\u76f8\u5173\u7684\uff0c\u540e\u9762\u7ae0\u8282\u4f1a\u8fdb\u884c\u8be6\u7ec6\u8ba8\u8bba\u3002 Instructions Machine instructions are normally the size of the architecture's word, such as in RISC architectures , or a multiple of the \"char\" size that is a fraction of it. This is a natural choice since instructions and data usually share the same memory subsystem. In Harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ESS electronic telephone switch had 37-bit instructions and 23-bit data words.","title":"Word(computer-architecture)"},{"location":"CPU/Word/Word(computer-architecture)/#word-computer-architecture","text":"In computing , a word is the natural unit of data used by a particular processor design. A word is a fixed-sized piece of data handled as a unit by the instruction set or the hardware of the processor. The number of bits in a word (the word size , word width , or word length ) is an important characteristic of any specific processor design or computer architecture . NOTE: \u6309\u7167Book-\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406-\u79d1\u5b66\u51fa\u7248\u793e\u76841.2.4 \u8ba1\u7b97\u673a\u7684\u6027\u80fd\u6307\u6807 \u4e2d\u7ed9\u51fa\u7684\u5b9a\u4e49\u6bd4\u8f83\u5bb9\u6613\u7406\u89e3\uff1a \u6307\u5904\u7406\u673a \u8fd0\u7b97\u5668 \uff08ALU\uff09\u4e2d\u4e00\u6b21\u80fd\u591f\u5b8c\u6210\u4e8c\u8fdb\u5236\u6570\u8fd0\u7b97\u7684 \u4f4d\u6570 The size of a word is reflected in many aspects of a computer's structure and operation; the majority of the registers in a processor are usually word sized and the largest piece of data that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. The largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).","title":"Word (computer architecture)"},{"location":"CPU/Word/Word(computer-architecture)/#uses-of-words","text":"Depending on how a computer is organized, word-size units may be used for:","title":"Uses of words"},{"location":"CPU/Word/Word(computer-architecture)/#fixed-point-numbers","text":"Holders for fixed point , usually integer , numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word \uff08programmer\u53ef\u4ee5\u636e\u6b64\u6765\u786e\u5b9aword size\uff09. The other sizes, if any, are likely to be multiples or fractions of the word size. The smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder.","title":"Fixed point numbers"},{"location":"CPU/Word/Word(computer-architecture)/#floating-point-numbers","text":"Holders for floating point numerical values are typically either a word or a multiple of a word.","title":"Floating point numbers"},{"location":"CPU/Word/Word(computer-architecture)/#addresses","text":"Holders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size. NOTE: \u5373\u6307\u9488\u7c7b\u578b\u7684\u957f\u5ea6","title":"Addresses"},{"location":"CPU/Word/Word(computer-architecture)/#registers","text":"Processor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. Many computer architectures use general-purpose registers that are capable of storing data in multiple representations. These registers must be sized to hold the largest of the available types. Historically, this determined the word size of the architecture.","title":"Registers"},{"location":"CPU/Word/Word(computer-architecture)/#memoryprocessor-transfer","text":"When the processor reads from the memory subsystem into a register or writes a register's value to memory, the amount of data transferred is often a word . Historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments. In simple memory subsystems, the word is transferred over the memory data bus , which typically has a width of a word or half-word. In memory subsystems that use caches , the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used. NOTE: \u8fd9\u4e2a\u975e\u5e38\u91cd\u8981\uff0c\u540e\u9762\u7684\u7ae0\u8282\u4f1a\u5bf9\u6b64\u8fdb\u884c\u8be6\u7ec6\u8ba8\u8bba","title":"Memory\u2013processor transfer"},{"location":"CPU/Word/Word(computer-architecture)/#unit-of-address-resolution","text":"In a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. In most computers, the unit is either a character (e.g. a byte) or a word. (A few computers have used bit resolution.) If the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. On the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation). NOTE: \u8fd9\u4e2a\u548c\u524d\u9762\u7684 Memory\u2013processor transfer \u662f\u7d27\u5bc6\u76f8\u5173\u7684\uff0c\u540e\u9762\u7ae0\u8282\u4f1a\u8fdb\u884c\u8be6\u7ec6\u8ba8\u8bba\u3002","title":"Unit of address resolution"},{"location":"CPU/Word/Word(computer-architecture)/#instructions","text":"Machine instructions are normally the size of the architecture's word, such as in RISC architectures , or a multiple of the \"char\" size that is a fraction of it. This is a natural choice since instructions and data usually share the same memory subsystem. In Harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ESS electronic telephone switch had 37-bit instructions and 23-bit data words.","title":"Instructions"}]}